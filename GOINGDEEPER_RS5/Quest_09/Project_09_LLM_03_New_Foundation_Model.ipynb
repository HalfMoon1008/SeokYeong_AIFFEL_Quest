{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b9663f",
   "metadata": {},
   "source": [
    "# 27. LLM Trend Note 2 [프로젝트_03]\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97bc05",
   "metadata": {},
   "source": [
    "## 27-1. 프로젝트: KoChatGPT 업그레이드 하기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eea688",
   "metadata": {},
   "source": [
    "#### 필수 requirement 설치 여부 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f488fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers                  4.28.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "!pip list | grep transformers # transformers 4.28.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95fed6",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e4660",
   "metadata": {},
   "source": [
    "### Base model (Ko-GPT-Trinity 1.2B로 foundation model 교체)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afba4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 허깅페이스의 transformers를 사용해 토크나이저와 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26364403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11f3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/ko-gpt-trinity-1.2B-v0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71e0273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354620f7fdac40c6843727cba5faf900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02502215a8d44b57885d3f2d83531c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda1f1e762e645f2a4686776dc0b4419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b75b592a8749ceaeaacf1c3a4b61fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe330bdfcb347d0913608b50ac12e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382257b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bc9795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko-gpt-trinity-1.2B 모델의 tokenizer가 입력받아 처리 가능한 최대 토큰 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bddc6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52784b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefee880",
   "metadata": {},
   "source": [
    "### 단계별( SFT, RM, PPO) 데이터셋 확인 및 EDA\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d275e8",
   "metadata": {},
   "source": [
    "#### 01-1 데이터셋(SFT) 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433a96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "data_path_1_SFT = '/aiffel/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4eef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(list_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a856baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_dict[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c5027",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a7a630",
   "metadata": {},
   "source": [
    "#### 01-2 데이터셋(SFT) EDA\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9fb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f52b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분류를 위한 기준\n",
    "def classify_tone(sentence):\n",
    "    if sentence.endswith('?'):\n",
    "        return \"질문형\"\n",
    "    elif sentence.endswith('.'):\n",
    "        return \"서술형\"\n",
    "    elif sentence.endswith('!'):\n",
    "        return \"감탄형\"\n",
    "    else:\n",
    "        return \"기타\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec2ee59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 불고기용 고기 한우에요? - Tone: 질문형\n",
      "Completion: '저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다. - Tone: 서술형\n",
      "----\n",
      "Prompt: 쓰던 앱이 유료로 전환됐어 - Tone: 기타\n",
      "Completion: '어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다. - Tone: 서술형\n",
      "----\n",
      "Prompt: 여친이랑 다툼 - Tone: 기타\n",
      "Completion: '저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다. - Tone: 서술형\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 문체 분석\n",
    "for item in list_data_dict[:3]:\n",
    "    prompt = item['prompt']\n",
    "    completion = item['completion']\n",
    "    \n",
    "    # 문체 분류\n",
    "    prompt_tone = classify_tone(prompt)\n",
    "    completion_tone = classify_tone(completion)\n",
    "    \n",
    "    print(f\"Prompt: {prompt} - Tone: {prompt_tone}\")\n",
    "    print(f\"Completion: {completion} - Tone: {completion_tone}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204ccdd",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad68dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 완성도 분석 (예시: 마지막에 마침표가 있는지로 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90b7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prompt'의 완성도 분석\n",
    "complete_prompts = [item['prompt'] for item in list_data_dict if item['prompt'].endswith('.')]\n",
    "incomplete_prompts = [item['prompt'] for item in list_data_dict if not item['prompt'].endswith('.')]\n",
    "\n",
    "# 'completion'의 완성도 분석\n",
    "complete_completions = [item['completion'] for item in list_data_dict if item['completion'].endswith('.')]\n",
    "incomplete_completions = [item['completion'] for item in list_data_dict if not item['completion'].endswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d39f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complete prompts: 588\n",
      "Number of incomplete prompts: 11412\n",
      "Number of complete completions: 10635\n",
      "Number of incomplete completions: 1365\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of complete prompts: {len(complete_prompts)}\")\n",
    "print(f\"Number of incomplete prompts: {len(incomplete_prompts)}\")\n",
    "print(f\"Number of complete completions: {len(complete_completions)}\")\n",
    "print(f\"Number of incomplete completions: {len(incomplete_completions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c3ad4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a60add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 길이 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b8c8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eadf6255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAGDCAYAAAAVh7eRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAz90lEQVR4nO3deZgdVZn48e+bEAgQSBAzbAETGEADWTAxBjDIMqzDoijbABMQBxlkcYNBEc0gKDrI6pIfDhhBhEAAyQCKARMVRSDBDlsUAwaSACEEkSWyhLy/P251ewm93G66uvt2vp/nuU9XnTr31HtPCvrtc0+disxEkiRJUufq090BSJIkSb2RibYkSZJUAhNtSZIkqQQm2pIkSVIJTLQlSZKkEphoS5IkSSUw0ZYktSoihkZERsQandjmkRHxi05s7+GI2LXYnhQRP+7Etr8UEf/bWe1JWn2YaEuqKxHxoYj4XUT8LSKej4jfRsQHOqHdYyLirs6IsTNFxIKI+Jd6OmdETImI1yPipeL1UER8IyIGNtbJzKszc68a2zqnrXqZuV1mzupozFXn2zUiFq3S9tcz85PvtG1Jqx8TbUl1IyLWB24BLgXeBWwG/DfwWnfGpWZ9KzPXAwYDxwLjgd9GxLqdeZLOHGWXpM5moi2pnmwDkJnXZOabmfn3zPxFZj7QWCEiPhER8yLirxFxe0S8p+pYRsQJEfHniHghIr4bFe8DJgM7RsTLEfFCUX+tiDg/Ip6MiCURMTki1i6O7RoRiyLi8xHxbEQ8HRHHVp1r7Yj4dkQ8UYy+31X13vHFqPwLETG3ccpDe0REn4g4IyIei4hlEXFdRLyrONY41WNiEftzEXHmKrH9qOijeRFxeuMobkRcBWwB/F/RF6dXnfbI5tprTWa+mpn3AQcCG1JJut/yDULxb3Bh0Y8vRsSDEbF9RBwPHAmcXsTyf0X9BRHxXxHxAPBKRKzRzCh8/4iYWoyo3x8Ro6o+f0bEP1ftT4mIc4o/An4GbFqc7+WI2DRWmYoSEQdGZarKCxExq7h+Go8tiIgvRMQDxb/71IjoX0tfSep9TLQl1ZNHgTeLJHHfiNig+mBEHAR8CTiYykjqb4BrVmljf+ADwEjgUGDvzJwHnADcnZkDMnNQUfc8Ksn9aOCfqYygf6WqrY2BgUX5ccB3q2I6HxgD7ERl9P10YGVEbAbcCpxTlH8BuCEiBrezL04GPgJ8GNgU+Cvw3VXqfAjYFtgD+EpVQvhVYCiwJbAncFTjGzLzaOBJ4ICiL75VQ3ttysyXgBnAhGYO7wXsQqWvB1L5d1mWmZcBV1MZHR+QmQdUvecI4F+BQZm5opk2DwKup9LHPwF+GhH92ojxFWBf4KnifAMy86nqOhGxDZVr6jNUrrHbqPxRsmZVtUOBfYBhVK6zY1o7r6Tey0RbUt3IzBepJHsJ/ABYGhHTI2KjosoJwDcyc16RfH0dGF09qg2cl5kvZOaTwEwqSfTbREQAxwOfzczni0Tx68DhVdXeAM7OzDcy8zbgZWDbiOgDfAI4NTMXF6Pvv8vM16gktbdl5m2ZuTIzZwCzgf3a2R0nAGdm5qKi3UnAx+OtUyn+uxj1nwvMBRpHdQ8Fvp6Zf83MRcAlNZ6zpfZq9RSVxHdVbwDrAe8Fovj3e7qNti7JzIWZ+fcWjs/JzGmZ+QZwAdCfyvSVd+ow4NbMnFG0fT6wNpU/qKpjeyoznwf+jxauMUm9n4m2pLpSJGHHZOYQYHsqo7kXFYffA1xcfKX/AvA8EFRGnBs9U7W9HBjQwqkGA+sAc6ra+3lR3mjZKqOpje29m0pi91gz7b4HOKSxzaLdDwGbtPa5W2jnpqo25gFvAhtV1Wnps24KLKw6Vr3dmlr7riWbUfk3eYvM/CXwHSoj8s9GxGVRmY/fmrZibjqemSuBRVQ+9zu1KfDEKm0vpGPXmKRezkRbUt3KzD8CU6gk3FBJeD6VmYOqXmtn5u9qaW6V/eeAvwPbVbU1MDNrSZqeA14Ftmrm2ELgqlViXDczz6uh3VXb2XeVdvpn5uIa3vs0MKRqf/NVjq/aF+9YRAwA/oXKdJ63ycxLMnMMMJzKFJLT2oilrRibPlPxDcMQKiPqUEl+16mqu3E72n2Kyh85jW1Hca5a+l3SasZEW1LdiIj3FjcfDin2N6cyV/f3RZXJwBcjYrvi+MCIOKTG5pcAQxrn2hYjlT8ALoyIfyra2ywi9m6roeK9VwAXFDfT9Y2IHSNiLeDHwAERsXdR3j8qN1YOaaXJfkW9xtcaxWc9t3FaTEQMLuao1+I6Kv20QTFn/KRm+mLLGttqVVRuKB0D/JTKPPIfNlPnAxHxwWIO9StU/khZ+Q5jGRMRBxd99RkqK9M0XicNwL8V/b8PlXnujZYAG0bVUoSruA7414jYo4j380XbtfwxJ2k1Y6ItqZ68BHwQuCciXqGSOD1EJdkhM28CvglcGxEvFsf2rbHtXwIPA89ExHNF2X8B84HfF+3dQeVmwFp8AXgQuI/KdIlvAn0ycyGVG/W+BCylMjJ9Gq3///g2KqPrja9JwMXAdOAXEfESlb74YI2xnU1lKsVfis80jbcukfgN4MvFtJQv1Njmqk4v4loGXAnMAXYqbjhc1fpU/qj5K5VpGcuA/ymOXQ4ML2L5aTvOfzOV+dR/BY4GDi7mVAOcChwAvEBlVZOmdotvSa4BHi/O+ZbpJpn5Jyrz7C+l8s3FAVRuHH29HbFJWk1EZqd/QyhJqiMR8Z/A4Zn54TYrS5Jq5oi2JK1mImKTiNg5Kmtxb0vlG4GbujsuSeptfKKWJK1+1gT+H5V1nl8ArgW+150BSVJv5NQRSZIkqQROHZEkSZJKYKItSZIklaBXztF+97vfnUOHDu3uMCRJktTLzZkz57nMHNzcsV6ZaA8dOpTZs2d3dxiSJEnq5SLiiZaOOXVEkiRJKoGJtiRJklQCE21JkiSpBL1yjrYkSVJHvPHGGyxatIhXX321u0NRD9O/f3+GDBlCv379an6PibYkSVJh0aJFrLfeegwdOpSI6O5w1ENkJsuWLWPRokUMGzas5vc5dUSSJKnw6quvsuGGG5pk6y0igg033LDd33SYaEuSJFUxyVZzOnJdmGhLkiT1IH379mX06NFsv/32HHLIISxfvrzLzj1r1ix+97vfNXtsypQpnHTSSaWde8GCBfzkJz/psvN1BedoS5IktWDSpK5vb+2116ahoQGAI488ksmTJ/O5z32u6fiKFStYY41yUrhZs2YxYMAAdtppp1Lab01jov1v//ZvXX7usjiiLUmS1ENNmDCB+fPnM2vWLCZMmMCBBx7I8OHDefXVVzn22GMZMWIEO+ywAzNnzgQqo8Af+chH2HPPPRk6dCjf+c53uOCCC9hhhx0YP348zz//PAC77rorp556atPI+b333suCBQuYPHkyF154IaNHj+Y3v/lNTTH++Mc/Zty4cYwePZpPfepTvPnmmwAMGDCAM888k1GjRjF+/HiWLFkCwGOPPcb48eMZMWIEX/7ylxkwYAAAZ5xxBr/5zW8YPXo0F154IQBPPfUU++yzD1tvvTWnn346AG+++SbHHHMM22+/PSNGjGiq2xOZaEuSJPVAK1as4Gc/+xkjRowA4P777+fiiy/m0Ucf5bvf/S4RwYMPPsg111zDxIkTm27Ue+ihh7jxxhu57777OPPMM1lnnXX4wx/+wI477siVV17Z1P7y5ctpaGjge9/7Hp/4xCcYOnQoJ5xwAp/97GdpaGhgwoQJbcY4b948pk6dym9/+1saGhro27cvV199NQCvvPIK48ePZ+7cueyyyy784Ac/AODUU0/l1FNP5cEHH2TIkCFNbZ133nlMmDCBhoYGPvvZzwLQ0NDA1KlTefDBB5k6dSoLFy6koaGBxYsX89BDD/Hggw9y7LHHdk6Hl8BEW5IkqQf5+9//zujRoxk7dixbbLEFxx13HADjxo1rWlrurrvu4qijjgLgve99L+95z3t49NFHAdhtt91Yb731GDx4MAMHDuSAAw4AYMSIESxYsKDpPEcccQQAu+yyCy+++CIvvPBCu2O98847mTNnDh/4wAcYPXo0d955J48//jgAa665Jvvvvz8AY8aMaTr33XffzSGHHALQ5jSRPfbYg4EDB9K/f3+GDx/OE088wZZbbsnjjz/OySefzM9//nPWX3/9dsfdVZyjLUmS1INUz9Gutu6669b0/rXWWqtpu0+fPk37ffr0YcWKFU3HVl1FoyOramQmEydO5Bvf+MbbjvXr16+pzb59+77l3LWq/iyNbWywwQbMnTuX22+/ncmTJ3PddddxxRVXtLvtruCIdheYNKnzb6aQJEmrrwkTJjRN0Xj00Ud58skn2XbbbdvVxtSpU4HK6PjAgQMZOHAg6623Hi+99FLNbeyxxx5MmzaNZ599FoDnn3+eJ554otX3jB8/nhtuuAGAa6+9tqm81nM/99xzrFy5ko997GOcc8453H///TXH29VMtCVJkurMiSeeyMqVKxkxYgSHHXYYU6ZMecvoby369+/PDjvswAknnMDll18OwAEHHMBNN93U4s2QU6ZMYciQIU2v9ddfn3POOYe99tqLkSNHsueee/L000+3et6LLrqICy64gJEjRzJ//nwGDhwIwMiRI+nbty+jRo1q9QbHxYsXs+uuuzJ69GiOOuqoZkfTe4rIzHIajugP/BpYi8oUlWmZ+dWIGAZcC2wIzAGOzszXI2It4EpgDLAMOCwzFxRtfRE4DngTOCUzb2/t3GPHjs3Zs2eX8rk6onE021FtSZJ6tnnz5vG+972vu8Mo3a677sr555/P2LFju/zcy5cvZ+211yYiuPbaa7nmmmu4+eabuzyOjmju+oiIOZnZbEeWOUf7NWD3zHw5IvoBd0XEz4DPARdm5rURMZlKAv394udfM/OfI+Jw4JvAYRExHDgc2A7YFLgjIrbJzDdLjF2SJEklmDNnDieddBKZyaBBg3rs/OrOUFqinZWh8peL3X7FK4HdgcZbTH8ETKKSaB9UbANMA74TlRn0BwHXZuZrwF8iYj4wDri7rNglSZJ6s1mzZnXbuSdMmMDcuXO77fxdqdQ52hHRNyIagGeBGcBjwAuZ2Xjb6SJgs2J7M2AhQHH8b1SmlzSVN/MeSZIkqUcqNdHOzDczczQwhMoo9HvLOldEHB8RsyNi9tKlS8s6jSRJklSTLll1JDNfAGYCOwKDIqJxysoQYHGxvRjYHKA4PpDKTZFN5c28p/ocl2Xm2MwcO3jw4DI+hiRJklSz0hLtiBgcEYOK7bWBPYF5VBLujxfVJgKNt5lOL/Ypjv+ymOc9HTg8ItYqVizZGri3rLglSZKkzlDmiPYmwMyIeAC4D5iRmbcA/wV8rripcUPg8qL+5cCGRfnngDMAMvNh4DrgEeDnwKddcUSSJPVWzzzzDIcffjhbbbUVY8aMYb/99mt6vHoZZs2a1fSo9JY0NDRw2223Ne1Pnz6d8847r1POP2DAgE5ppyUXXXQRy5cv77LzVStz1ZEHgB2aKX+cynztVctfBQ5poa1zgXM7O0ZJkqRWdfZDMNpoLzP56Ec/ysSJE5uemjh37lyWLFnCNtts07mxtENDQwOzZ89mv/32A+DAAw/kwAMP7LZ42uOiiy7iqKOOYp111unyc/tkSEmSpB5i5syZ9OvXjxNOOKGpbNSoUUyYMIHM5LTTTmP77bdnxIgRTY9QnzVrFh/+8Ic56KCD2HLLLTnjjDO4+uqrGTduHCNGjOCxxx4D4JhjjuGEE05g7NixbLPNNtxyyy1vO/8rr7zCJz7xCcaNG8cOO+zAzTffzOuvv85XvvIVpk6dyujRo5k6dSpTpkzhpJNOAmDBggXsvvvujBw5kj322IMnn3yy6XynnHIKO+20E1tuuSXTpk2ruR8ee+wx9tlnH8aMGcOECRP44x//2GqbK1eu5MQTT+S9730ve+65J/vttx/Tpk3jkksu4amnnmK33XZjt912a2r/zDPPZNSoUYwfP54lS5YAcP3117P99tszatQodtlll5pjbY2JtiRJUg/x0EMPMWbMmGaP3XjjjTQ0NDB37lzuuOMOTjvttKbHnc+dO5fJkyczb948rrrqKh599FHuvfdePvnJT3LppZc2tbFgwQLuvfdebr31Vk444QReffXVt5zj3HPPZffdd+fee+9l5syZnHbaabzxxhucffbZHHbYYTQ0NHDYYYe95T0nn3wyEydO5IEHHuDII4/klFNOaTr29NNPc9ddd3HLLbdwxhln1NwPxx9/PJdeeilz5szh/PPP58QTT2y1zRtvvJEFCxbwyCOPcNVVV3H33ZXHrZxyyilsuummzJw5k5kzZwKVPybGjx/P3Llz2WWXXfjBD34AwNlnn83tt9/O3LlzmT59es2xtqbMJ0NKkiSpk9x1110cccQR9O3bl4022ogPf/jD3Hfffay//vp84AMfYJNNNgFgq622Yq+99gJgxIgRTQkmwKGHHkqfPn3Yeuut2XLLLZtGihv94he/YPr06Zx//vkAvPrqq00j1C25++67ufHGGwE4+uijOf3005uOfeQjH6FPnz4MHz68aeS4LS+//DK/+93vOOSQf8wofu2111pt86677uKQQw6hT58+bLzxxm8ZvV7Vmmuu2TQnfcyYMcyYMQOAnXfemWOOOYZDDz2Ugw8+uKZY22KiLUmS1ENst9127Zpi0WittdZq2u7Tp0/Tfp8+fVixYkXTscpDt2lxPzO54YYb2Hbbbd9Sfs8997Q7plXjqiwm17aVK1cyaNAgGhoaOq3Nav369Wv63H379m3qn8mTJ3PPPfdw6623MmbMGObMmcOGG27Y7varOXVEkiSph9h999157bXXuOyyy5rKHnjgAX7zm98wYcIEpk6dyptvvsnSpUv59a9/zbhxb1tfolXXX389K1eu5LHHHuPxxx9/W0K99957c+mllzYlsH/4wx8AWG+99XjppZeabXOnnXZqunHz6quvZsKECe2KaVXrr78+w4YN4/rrrwcqyXRbj2zfeeedueGGG1i5ciVLlix5yyPmW4u92mOPPcYHP/hBzj77bAYPHszChQvbfE9bTLQlSZJ6iIjgpptu4o477mCrrbZiu+2244tf/CIbb7wxH/3oRxk5ciSjRo1i991351vf+hYbb7xxu9rfYostGDduHPvuuy+TJ0+mf//+bzl+1lln8cYbbzBy5Ei22247zjrrLAB22203HnnkkaabIatdeuml/PCHP2TkyJFcddVVXHzxxe2Kafny5QwZMqTpdcEFF3D11Vdz+eWXM2rUKLbbbjtuvvnmVtv42Mc+xpAhQxg+fDhHHXUU73//+xk4cCBQme+9zz77tDqdBOC0005jxIgRbL/99uy0006MGjWqXZ+jOdGRIfeebuzYsTl79uzuDqNJ40o+nb1CkCRJ6lzz5s3jfe97X3eHUYpjjjmG/fffn49//ONtV65DL7/8MgMGDGDZsmWMGzeO3/72t+3+Q6QtzV0fETEnM8c2V9852pIkSap7+++/Py+88AKvv/46Z511Vqcn2R1hoi1JkrQamDJlSneHUKrqedk9hXO0JUmSpBKYaEuSJFXpjfev6Z3ryHVhoi1JklTo378/y5YtM9nWW2Qmy5Yte9sqLW1xjrYkSVJhyJAhLFq0iKVLl3Z3KOph+vfvz5AhQ9r1HhNtSZKkQr9+/Rg2bFh3h6FewqkjkiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpQWqIdEZtHxMyIeCQiHo6IU4vySRGxOCIaitd+Ve/5YkTMj4g/RcTeVeX7FGXzI+KMsmKWJEmSOssaJba9Avh8Zt4fEesBcyJiRnHswsw8v7pyRAwHDge2AzYF7oiIbYrD3wX2BBYB90XE9Mx8pMTYSzFp0lt/SpIkqfcqLdHOzKeBp4vtlyJiHrBZK285CLg2M18D/hIR84FxxbH5mfk4QERcW9Stu0RbkiRJq48umaMdEUOBHYB7iqKTIuKBiLgiIjYoyjYDFla9bVFR1lL5quc4PiJmR8TspUuXdvZHkCRJktql9EQ7IgYANwCfycwXge8DWwGjqYx4f7szzpOZl2Xm2MwcO3jw4M5oUpIkSeqwMudoExH9qCTZV2fmjQCZuaTq+A+AW4rdxcDmVW8fUpTRSrkkSZLUI5W56kgAlwPzMvOCqvJNqqp9FHio2J4OHB4Ra0XEMGBr4F7gPmDriBgWEWtSuWFyellxS5IkSZ2hzBHtnYGjgQcjoqEo+xJwRESMBhJYAHwKIDMfjojrqNzkuAL4dGa+CRARJwG3A32BKzLz4RLjliRJkt6xMlcduQuIZg7d1sp7zgXObab8ttbeJ0mSJPU0PhlSkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKkGbiXZErBsRfYrtbSLiwIjoV35okiRJUv2qZUT710D/iNgM+AVwNDClzKAkSZKkeldLoh2ZuRw4GPheZh4CbFduWJIkSVJ9qynRjogdgSOBW4uyvuWFJEmSJNW/WhLtzwBfBG7KzIcjYktgZqlRSZIkSXVujbYqZOavgF9FxDrF/uPAKWUHJkmSJNWzWlYd2TEiHgH+WOyPiojvlR6ZJEmSVMdqmTpyEbA3sAwgM+cCu5QYkyRJklT3anpgTWYuXKXozRJikSRJknqNWhLthRGxE5AR0S8ivgDMa+tNEbF5RMyMiEci4uGIOLUof1dEzIiIPxc/NyjKIyIuiYj5EfFARLy/qq2JRf0/R8TEDn5WSZIkqcvUkmifAHwa2AxYDIwu9tuyAvh8Zg4HxgOfjojhwBnAnZm5NXBnsQ+wL7B18Toe+D5UEnPgq8AHgXHAVxuTc0mSJKmnqmXVkeeorKHdLpn5NPB0sf1SRMyjkqwfBOxaVPsRMAv4r6L8ysxM4PcRMSgiNinqzsjM5wEiYgawD3BNe2OSJEmSukotq478KCIGVe1vEBFXtOckETEU2AG4B9ioSMIBngE2KrY3A6rngi8qyloqX/Ucx0fE7IiYvXTp0vaEJ0mSJHW6WqaOjMzMFxp3MvOvVJLmmkTEAOAG4DOZ+WL1sWL0OmttqzWZeVlmjs3MsYMHD+6MJiVJkqQOqyXR7lM9J7qYM93mlJOibj8qSfbVmXljUbykmBJC8fPZonwxsHnV24cUZS2VS5IkST1WLYn2t4G7I+JrEXEO8DvgW229KSICuByYl5kXVB2aDjSuHDIRuLmq/N+L1UfGA38rppjcDuxVTFnZANirKJMkSZJ6rFpuhrwyIuYAuxVFB2fmIzW0vTNwNPBgRDQUZV8CzgOui4jjgCeAQ4tjtwH7AfOB5cCxxfmfj4ivAfcV9c5uvDFSkiRJ6qlqmgJC5fHrf22sHxFbZOaTrb0hM+8CooXDezRTP2lh2cDMvAJo1w2Y3W3SpO6OQJIkSd2pzUQ7Ik6mso71EipPhAwqNzCOLDc0SZIkqX7VMqJ9KrBtZi4rOxhJkiSpt6jpEezA38oORJIkSepNahnRfhyYFRG3Aq81Fq6ykogkSZKkKrUk2k8WrzWLlyRJkqQ21LK8338DRMQ6mbm8/JAkSZKk+tfmHO2I2DEiHqGyxB8RMSoivld6ZJIkSVIdq+VmyIuAvYFlAJk5F9ilxJgkSZKkuldLok1mLlyl6M0SYpEkSZJ6jVpuhlwYETsBGRH9qKyrPa/csCRJkqT6VsuI9glUHo2+GbAYGA2cWGJMkiRJUt2rZUR728w8srogInYGfltOSJIkSVL9q2VE+9IayyRJkiQVWhzRjogdgZ2AwRHxuapD6wN9yw5MkiRJqmetTR1ZExhQ1FmvqvxF4ONlBiVJkiTVuxYT7cz8FfCriJiSmU90YUySJElS3avlZsi1IuIyYGh1/czcvaygJEmSpHpXS6J9PTAZ+F98UI0kSZJUk1oS7RWZ+f3SI5EkSZJ6kVqW9/u/iDgxIjaJiHc1vkqPTJIkSapjtYxoTyx+nlZVlsCWnR+OJEmS1Du0mWhn5rCuCEQlmzSp3PqSJEl6izanjkTEOhHx5WLlESJi64jYv/zQJEmSpPpVyxztHwKvU3lKJMBi4JzSIpIkSZJ6gVoS7a0y81vAGwCZuRyIUqOSJEmS6lwtN0O+HhFrU7kBkojYCnit1KhWR86hliRJ6lVqSbS/Cvwc2DwirgZ2Bo4pMyhJkiSp3tWy6siMiLgfGE9lysipmflc6ZFJkiRJdazFOdoR8Z6IGAiQmcuA5cCewL9HxJpdFJ8kSZJUl1q7GfI6YF2AiBgNXA88CYwCvld6ZJIkSVIda23qyNqZ+VSxfRRwRWZ+OyL6AA2lR6bWeTOkJElSj9baiHb1En67A3cCZObKUiNaDUyaZJ4sSZLU27U2ov3LiLgOeBrYAPglQERsQuUBNpIkSZJa0Fqi/RngMGAT4EOZ+UZRvjFwZslxSZIkSXWtxUQ7MxO4tpnyP5QakSRJktQL1PIIdkmSJEntZKItSZIklaC1B9bcWfz8ZteFI0mSJPUOrd0MuUlE7AQcGBHX8tbl/sjM+0uNTJIkSapjrSXaXwHOAoYAF6xyLKmsrS1JkiSpGa2tOjINmBYRZ2Xm17owJkmSJKnutTaiDUBmfi0iDgR2KYpmZeYt5YYlSZIk1bc2Vx2JiG8ApwKPFK9TI+LrNbzvioh4NiIeqiqbFBGLI6KheO1XdeyLETE/Iv4UEXtXle9TlM2PiDPa+wElSZKk7tDmiDbwr8DozFwJEBE/Av4AfKmN900BvgNcuUr5hZl5fnVBRAwHDge2AzYF7oiIbYrD3wX2BBYB90XE9Mx8pIa4JUmSpG5T6zrag6q2B9byhsz8NfB8je0fBFybma9l5l+A+cC44jU/Mx/PzNepPKnyoBrblCRJkrpNLYn2N4A/RMSUYjR7DnDuOzjnSRHxQDG1ZIOibDNgYVWdRUVZS+VvExHHR8TsiJi9dOnSdxCeJEmS9M61mWhn5jXAeOBG4AZgx8yc2sHzfR/YChgNPA18u4PtvE1mXpaZYzNz7ODBgzurWUmSJKlDapmjTWY+DUx/pyfLzCWN2xHxA6Bx9ZLFwOZVVYcUZbRSLkmSJPVYtc7R7hQRsUnV7keBxhVJpgOHR8RaETEM2Bq4F7gP2DoihkXEmlRumHzHCb8kSZJUtppGtDsiIq4BdgXeHRGLgK8Cu0bEaCpPllwAfAogMx+OiOuoLB+4Avh0Zr5ZtHMScDvQF7giMx8uK+ZOM2kSu86qpV7JcUiSJKnbtJpoR0Rf4OHMfG97G87MI5opvryV+ufSzE2WmXkbcFt7zy9JkiR1p1anjhSjyn+KiC26KB5JkiSpV6hl6sgGwMMRcS/wSmNhZh5YWlSSJElSnasl0T6r9CgkSZKkXqbNRDszfxUR7wG2zsw7ImIdKjcmSpIkSWpBm8v7RcR/ANOA/1cUbQb8tMSYJEmSpLpXyzranwZ2Bl4EyMw/A/9UZlCSJElSvatljvZrmfl6RAAQEWtQWQdbvdmkSeXWlyRJ6uVqGdH+VUR8CVg7IvYErgf+r9ywJEmSpPpWS6J9BrAUeJDKkxxvA75cZlCSJElSvatl1ZGVEfEj4B4qU0b+lJlOHZEkSZJa0WaiHRH/CkwGHgMCGBYRn8rMn5UdnCRJklSvarkZ8tvAbpk5HyAitgJuBUy0JUmSpBbUMkf7pcYku/A48FJJ8UiSJEm9Qosj2hFxcLE5OyJuA66jMkf7EOC+LohNkiRJqlutTR05oGp7CfDhYnspsHZpEUmSJEm9QIuJdmYe25WBSJIkSb1JLauODANOBoZW18/MA8sLS5IkSapvtaw68lPgcipPg1xZajSSJElSL1FLov1qZl5SeiSSJElSL1JLon1xRHwV+AXwWmNhZt5fWlSSJElSnasl0R4BHA3szj+mjmSxL0mSJKkZtSTahwBbZubrZQcjSZIk9Ra1PBnyIWBQyXFIkiRJvUotI9qDgD9GxH28dY62y/vpHyZNKre+JElSnakl0f5q6VFIkiRJvUybiXZm/qorApEkSZJ6k1qeDPkSlVVGANYE+gGvZOb6ZQYmSZIk1bNaRrTXa9yOiAAOAsaXGZQkSZJU72pZdaRJVvwU2LuccCRJkqTeoZapIwdX7fYBxgKvlhaRJEmS1AvUsurIAVXbK4AFVKaPSJIkSWpBLXO0j+2KQCRJkqTepMVEOyK+0sr7MjO/VkI8kiRJUq/Q2oj2K82UrQscB2wImGhLkiRJLWgx0c7MbzduR8R6wKnAscC1wLdbep8kSZKkNuZoR8S7gM8BRwI/At6fmX/tisAkSZKketbaHO3/AQ4GLgNGZObLXRaVJEmSVOdae2DN54FNgS8DT0XEi8XrpYh4sWvCkyRJkupTa3O02/XUSEmSJEn/YDItSZIklcBEW5IkSSqBibYkSZJUgtIS7Yi4IiKejYiHqsreFREzIuLPxc8NivKIiEsiYn5EPBAR7696z8Si/p8jYmJZ8UqSJEmdqcwR7SnAPquUnQHcmZlbA3cW+wD7AlsXr+OB70PTOt5fBT4IjAO+2pic9wazZv3jJUmSpN6ltEQ7M38NPL9K8UFUHnxD8fMjVeVXZsXvgUERsQmwNzAjM58vHpQzg7cn75IkSVKP09VztDfKzKeL7WeAjYrtzYCFVfUWFWUtlb9NRBwfEbMjYvbSpUs7N2pJkiSpnbrtZsjMTCA7sb3LMnNsZo4dPHhwZzUrSZIkdUhXJ9pLiikhFD+fLcoXA5tX1RtSlLVULkmSJPVoXZ1oTwcaVw6ZCNxcVf7vxeoj44G/FVNMbgf2iogNipsg9yrKJEmSpB6txUewv1MRcQ2wK/DuiFhEZfWQ84DrIuI44Ang0KL6bcB+wHxgOXAsQGY+HxFfA+4r6p2dmaveYClJkiT1OKUl2pl5RAuH9mimbgKfbqGdK4ArOjE0SZIkqXQ+GVKSJEkqgYm2JEmSVAITbUmSJKkEJtqSJElSCUy0JUmSpBKYaEuSJEklMNGWJEmSSmCiLUmSJJWgtAfWSK2aNKnc+pIkSd3MEW1JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQSmGhLkiRJJTDRliRJkkpgoi1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbaPcSsWZWXJEmSegcTbUmSJKkEJtqSJElSCUy0JUmSpBKYaEuSJEklMNGWJEmSSmCiLUmSJJXARFuSJEkqgYm2JEmSVAITbUmSJKkEJtqSJElSCUy0JUmSpBKs0d0BSDWZNKlr3iNJktRJHNGWJEmSSmCiLUmSJJWgWxLtiFgQEQ9GRENEzC7K3hURMyLiz8XPDYryiIhLImJ+RDwQEe/vjpglSZKk9ujOEe3dMnN0Zo4t9s8A7szMrYE7i32AfYGti9fxwPe7PFJJkiSpnXrS1JGDgB8V2z8CPlJVfmVW/B4YFBGbdEN8kiRJUs26K9FO4BcRMSciji/KNsrMp4vtZ4CNiu3NgIVV711UlEmSJEk9Vnct7/ehzFwcEf8EzIiIP1YfzMyMiGxPg0XCfjzAFlts0XmRSpIkSR3QLSPambm4+PkscBMwDljSOCWk+PlsUX0xsHnV24cUZau2eVlmjs3MsYMHDy4zfEmSJKlNXZ5oR8S6EbFe4zawF/AQMB2YWFSbCNxcbE8H/r1YfWQ88LeqKSaSJElSj9QdU0c2Am6KiMbz/yQzfx4R9wHXRcRxwBPAoUX924D9gPnAcuDYrg9ZkiRJap8uT7Qz83FgVDPly4A9milP4NNdEJokSZLUaXrS8n6SJElSr2GiLUmSJJXARFuSJEkqgYm2JEmSVAITbUmSJKkEJtqSJElSCUy0JUmSpBKYaPcws2ZVXpIkSapvJtqSJElSCUy0JUmSpBJ0+SPYpS4zaVK59SVJklrhiLYkSZJUAhNtSZIkqQQm2pIkSVIJTLQlSZKkEphoS5IkSSUw0ZYkSZJKYKItSZIklcBEW5IkSSqBibYkSZJUAhNtSZIkqQQm2pIkSVIJTLQlSZKkEphod7JJk2DWrO6OQpIkSd3NRFuSJEkqwRrdHYCaVz0qvuuu3RXFambSpHLrS5Kk1Yoj2pIkSVIJTLQlSZKkEphoS5IkSSUw0ZYkSZJKYKItSZIklcBEW5IkSSqBy/tJHeVygJIkqRWOaEuSJEklMNGWJEmSSuDUkTrQ+JRInxC5mnFqiiRJdc1EW+oqJsKSJK1WnDoiSZIklcARbam3cKqJJEk9iol2HXGutjpVRxJtk3NJkmpmol2HGhNuMOlWD+couyRpNWaiLal2PS0RLjuenvZ5JUl1pW4S7YjYB7gY6Av8b2ae180hSepsPS2xdURekvQO1MWqIxHRF/gusC8wHDgiIoZ3b1Q9w6xZb51KIkmSpJ6hXka0xwHzM/NxgIi4FjgIeKRbo+pBvFFS6gF64oh2T4xJklYT9ZJobwYsrNpfBHywm2Lp0do7ur1qYt7c+xvrNHcTpgm+1MOZaLetp/WRU5akXiMys7tjaFNEfBzYJzM/WewfDXwwM0+qqnM8cHyxuy3wpy4PtOLdwHPddO56Zr91nH3XMfZbx9hvHWffdYz91nH2Xce0t9/ek5mDmztQLyPai4HNq/aHFGVNMvMy4LKuDKo5ETE7M8d2dxz1xn7rOPuuY+y3jrHfOs6+6xj7rePsu47pzH6ri5shgfuArSNiWESsCRwOTO/mmCRJkqQW1cWIdmauiIiTgNupLO93RWY+3M1hSZIkSS2qi0QbIDNvA27r7jhq0O3TV+qU/dZx9l3H2G8dY791nH3XMfZbx9l3HdNp/VYXN0NKkiRJ9aZe5mhLkiRJdcVEu5NExD4R8aeImB8RZ3R3PD1NRGweETMj4pGIeDgiTi3K3xURMyLiz8XPDYryiIhLiv58ICLe372foHtFRN+I+ENE3FLsD4uIe4r+mVrcJExErFXszy+OD+3WwLtRRAyKiGkR8ceImBcRO3q91SYiPlv8d/pQRFwTEf295t4uIq6IiGcj4qGqsnZfYxExsaj/54iY2B2fpau10Hf/U/z3+kBE3BQRg6qOfbHouz9FxN5V5avV797m+q3q2OcjIiPi3cW+11yVlvouIk4urruHI+JbVeWdc81lpq93+KJyg+ZjwJbAmsBcYHh3x9WTXsAmwPuL7fWAR4HhwLeAM4ryM4BvFtv7AT8DAhgP3NPdn6Gb++9zwE+AW4r964DDi+3JwH8W2ycCk4vtw4Gp3R17N/bZj4BPFttrAoO83mrqt82AvwBrF/vXAcd4zTXbV7sA7wceqipr1zUGvAt4vPi5QbG9QXd/tm7qu72ANYrtb1b13fDi9+pawLDi923f1fF3b3P9VpRvTmXBiCeAd3vN1XzN7QbcAaxV7P9TZ19zjmh3jqZHxGfm60DjI+JVyMynM/P+YvslYB6VX+gHUUmIKH5+pNg+CLgyK34PDIqITbo26p4hIoYA/wr8b7EfwO7AtKLKqv3W2J/TgD2K+quViBhI5X+qlwNk5uuZ+QJeb7VaA1g7ItYA1gGexmvubTLz18DzqxS39xrbG5iRmc9n5l+BGcA+pQffzZrru8z8RWauKHZ/T+WZGVDpu2sz87XM/Aswn8rv3dXud28L1xzAhcDpQPWNd15zVVrou/8EzsvM14o6zxblnXbNmWh3juYeEb9ZN8XS4xVfLe8A3ANslJlPF4eeATYqtu3Tf7iIyv9AVxb7GwIvVP1Cqu6bpn4rjv+tqL+6GQYsBX4YlSk3/xsR6+L11qbMXAycDzxJJcH+GzAHr7latfca89pr3ieojMaCfdeqiDgIWJyZc1c5ZL+1bRtgQjHt7VcR8YGivNP6zkRbXSoiBgA3AJ/JzBerj2Xl+xqXwakSEfsDz2bmnO6Opc6sQeUrwu9n5g7AK1S+xm/i9da8Yk7xQVT+WNkUWJfVYLSrDF5jHRMRZwIrgKu7O5aeLiLWAb4EfKW7Y6lTa1CZQjMeOA24rrO/kTPR7hxtPiJeEBH9qCTZV2fmjUXxksav6IufjV/b2KcVOwMHRsQCKl9R7Q5cTOUrwMZ18Kv7pqnfiuMDgWVdGXAPsQhYlJn3FPvTqCTeXm9t+xfgL5m5NDPfAG6kch16zdWmvdeY116ViDgG2B84svhDBey71mxF5Y/iucXviSHA/RGxMfZbLRYBNxbTa+6l8s3xu+nEvjPR7hw+Ir4NxV+IlwPzMvOCqkPTgcY7nicCN1eV/3tx1/R44G9VX8euNjLzi5k5JDOHUrmufpmZRwIzgY8X1Vbtt8b+/HhRf7UbUcvMZ4CFEbFtUbQH8Aheb7V4EhgfEesU/9029p3XXG3ae43dDuwVERsU3ybsVZStdiJiHyrT5A7MzOVVh6YDh0dlhZthwNbAvfi7l8x8MDP/KTOHFr8nFlFZeOAZvOZq8VMqN0QSEdtQucHxOTrzmuvsuzpX1xeVu3sfpXI36pndHU9PewEfovIV6gNAQ/Haj8pczjuBP1O58/ddRf0Avlv054PA2O7+DN39AnblH6uObFn8Rz8fuJ5/3DHdv9ifXxzfsrvj7sb+Gg3MLq65n1K5u97rrba++2/gj8BDwFVU7rz3mnt7P11DZR77G1QSnOM6co1RmY88v3gd292fqxv7bj6V+a+NvyMmV9U/s+i7PwH7VpWvVr97m+u3VY4v4B+rjnjNtX3NrQn8uPh/3f3A7p19zflkSEmSJKkETh2RJEmSSmCiLUmSJJXARFuSJEkqgYm2JEmSVAITbUmSJKkEJtqS1EtExMslt/+Z4kl0XXI+Sap3JtqSpFp9BlinrUqSpIo12q4iSapXEbEVlYdWDAaWA/+RmX+MiCnAi8BYYGPg9MycFhF9gO8Au1N5eMgbwBXApsVrZkQ8l5mNT1M7l8ojs/8OHJSZS7ry80lST+aItiT1bpcBJ2fmGOALwPeqjm1C5amt+wPnFWUHA0OB4cDRwI4AmXkJ8BSwW2OSDawL/D4zRwG/Bv6j1E8iSXXGEW1J6qUiYgCwE3B9RDQWr1VV5aeZuRJ4JCI2Kso+BFxflD8TETNbOcXrwC3F9hxgz04LXpJ6ARNtSeq9+gAvZOboFo6/VrUdLdRpzRuZmcX2m/g7RZLewqkjktRLZeaLwF8i4hCAqBjVxtt+C3wsIvoUo9y7Vh17CVivlGAlqRcy0Zak3mOdiFhU9foccCRwXETMBR4GDmqjjRuARcAjwI+B+4G/FccuA37exnQSSVIh/vGtnyRJlbndmflyRGwI3AvsnJnPdHdcklRvnE8nSVrVLRExCFgT+JpJtiR1jCPakiRJUgmcoy1JkiSVwERbkiRJKoGJtiRJklQCE21JkiSpBCbakiRJUglMtCVJkqQS/H8+E6sZyNGEZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 'prompt'와 'completion'의 길이를 모두 고려\n",
    "lengths_prompt = [len(item['prompt']) for item in list_data_dict]\n",
    "lengths_completion = [len(item['completion']) for item in list_data_dict]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 'prompt' 길이 분포\n",
    "plt.hist(lengths_prompt, bins=50, color='blue', alpha=0.5, label='Prompt Lengths')\n",
    "\n",
    "# 'completion' 길이 분포\n",
    "plt.hist(lengths_completion, bins=50, color='red', alpha=0.5, label='Completion Lengths')\n",
    "\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809b24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size: 12000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original data size: {len(list_data_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556d942",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028eb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 기반 필터링 (지나치게 긴 문장이나 지나치게 짧은 문장을 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe322448",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PROMPT_LENGTH = 5\n",
    "MAX_PROMPT_LENGTH = 50\n",
    "MIN_COMPLETION_LENGTH = 5\n",
    "MAX_COMPLETION_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46c5d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    item for item in list_data_dict \n",
    "    if MIN_PROMPT_LENGTH <= len(item['prompt']) <= MAX_PROMPT_LENGTH\n",
    "    and MIN_COMPLETION_LENGTH <= len(item['completion']) <= MAX_COMPLETION_LENGTH\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e116a49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data size: 10577\n"
     ]
    }
   ],
   "source": [
    "print(f\"Filtered data size: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc42df",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e8a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거 ('prompt'와 'completion' 모두를 기반으로 중복 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5910f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "unique_data = []\n",
    "for item in filtered_data:\n",
    "    combined_sentence = item['prompt'] + ' ' + item['completion']\n",
    "    if combined_sentence not in seen:\n",
    "        unique_data.append(item)\n",
    "        seen.add(combined_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0d39366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique data size after removing duplicates: 10577\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique data size after removing duplicates: {len(unique_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928ce2e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f21ef",
   "metadata": {},
   "source": [
    "#### 01-3 데이터셋(SFT) Augmentation\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4da0b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk에서 wordnet을 사용하기 위해 필요한 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0283b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9931e0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /aiffel/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eeec0d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d5daa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synonym Replacement: 문장 내의 단어를 그 단어의 동의어로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e7042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(words, n=5):\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word.isalnum()]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n: \n",
    "            break\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2edb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonym = lemma.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym)\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e18a74a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54aaf515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Deletion: 문장 내의 단어를 무작위로 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50c0f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(words, p=0.5): \n",
    "    if len(words) == 1: \n",
    "        return words\n",
    "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
    "    if len(remaining) == 0: \n",
    "        return [random.choice(words)]\n",
    "    else:\n",
    "        return remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1529ed",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "677ce1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Swap: 문장 내의 두 단어의 위치를 무작위로 바꿈."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dde3a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(sentence, n=5): \n",
    "    length = range(len(sentence))\n",
    "    if len(sentence) < 2:  # Check if the sentence has less than 2 words\n",
    "        return sentence\n",
    "    for _ in range(n):\n",
    "        idx1, idx2 = random.sample(length, 2)\n",
    "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b672ce",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e493524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_sentence(sentence, num_new_sentences=5):\n",
    "    augmented_sentences = []\n",
    "    words = sentence.split(' ')\n",
    "    for _ in range(num_new_sentences):\n",
    "        if random.uniform(0, 1) < 0.5:\n",
    "            new_sentence_words = synonym_replacement(words)\n",
    "        else:\n",
    "            new_sentence_words = random_swap(words)\n",
    "        augmented_sentences.append(' '.join(new_sentence_words))\n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63057681",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f93b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = []\n",
    "for item in filtered_data:\n",
    "    augmented_data.append(item)\n",
    "    prompt = item['prompt']\n",
    "    completion = item['completion']\n",
    "    for new_prompt in augment_sentence(prompt):\n",
    "        new_data = item.copy()\n",
    "        new_data['prompt'] = new_prompt\n",
    "        augmented_data.append(new_data)\n",
    "    for new_completion in augment_sentence(completion):\n",
    "        new_data = item.copy()\n",
    "        new_data['completion'] = new_completion\n",
    "        augmented_data.append(new_data)\n",
    "    if len(augmented_data) >= 15000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f6d66a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data size: 15004\n"
     ]
    }
   ],
   "source": [
    "print(f\"Augmented data size: {len(augmented_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b4847",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7ee33",
   "metadata": {},
   "source": [
    "#### 01-4 변경 파일(전처리+증강) 저장\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61e5245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 경로 및 파일명\n",
    "file_path = '/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kogpt_trinity/kogpt_trinity_1_SFT.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "effcf7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 쓰기 모드로 파일 열기\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in augmented_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394343f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f2693",
   "metadata": {},
   "source": [
    "#### 02-1 데이터셋(RM) 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "925c3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11a42613",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_2_RM = '/aiffel/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0f27a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    }
   ],
   "source": [
    "print(len(list_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53756586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_dict[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef5330",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6bf73c",
   "metadata": {},
   "source": [
    "#### 02-2 데이터셋(RM) EDA\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b21b45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90b92c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분류를 위한 기준\n",
    "def classify_tone(sentence):\n",
    "    if sentence.endswith('?'):\n",
    "        return \"질문형\"\n",
    "    elif sentence.endswith('.'):\n",
    "        return \"서술형\"\n",
    "    elif sentence.endswith('!'):\n",
    "        return \"감탄형\"\n",
    "    else:\n",
    "        return \"기타\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac37ce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나? - Tone: 질문형\n",
      "Completion_1: Allow me to answer your question. I know that you are curious about me. - Tone: 서술형\n",
      "Completion_2: 번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다. - Tone: 서술형\n",
      "Completion_3: 라이언에게 말했다. - Tone: 서술형\n",
      "----\n",
      "Prompt: 개포주공아파트는 몇 단지로 이루어져 있나? - Tone: 질문형\n",
      "Completion_1: 개포주공아파트는 다섯 단지로 이루어져 있습니다. - Tone: 서술형\n",
      "Completion_2: 이날 목송에서 구글상위노 - Tone: 기타\n",
      "Completion_3: 개포주공아파트는 총 27개 단지로 이루어져 있습니다. - Tone: 서술형\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 문체 분석\n",
    "for item in list_data_dict[:2]:\n",
    "    prompt = item['prompt']\n",
    "    completions = [item['completion_0'], item['completion_1'], item['completion_2']]\n",
    "    \n",
    "    # 문체 분류\n",
    "    prompt_tone = classify_tone(prompt)\n",
    "    print(f\"Prompt: {prompt} - Tone: {prompt_tone}\")\n",
    "    \n",
    "    for idx, completion in enumerate(completions, start=1):\n",
    "        completion_tone = classify_tone(completion)\n",
    "        print(f\"Completion_{idx}: {completion} - Tone: {completion_tone}\")\n",
    "    \n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0624856",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10ad81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 완성도 분석 (예시: 마지막에 마침표가 있는지로 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b516915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prompt'의 완성도 분석\n",
    "complete_prompts = [item['prompt'] for item in list_data_dict if item['prompt'].endswith('.')]\n",
    "incomplete_prompts = [item['prompt'] for item in list_data_dict if not item['prompt'].endswith('.')]\n",
    "\n",
    "# 'completion'의 완성도 분석\n",
    "complete_completions_0 = [item['completion_0'] for item in list_data_dict if item['completion_0'].endswith('.')]\n",
    "incomplete_completions_0 = [item['completion_0'] for item in list_data_dict if not item['completion_0'].endswith('.')]\n",
    "\n",
    "complete_completions_1 = [item['completion_1'] for item in list_data_dict if item['completion_1'].endswith('.')]\n",
    "incomplete_completions_1 = [item['completion_1'] for item in list_data_dict if not item['completion_1'].endswith('.')]\n",
    "\n",
    "complete_completions_2 = [item['completion_2'] for item in list_data_dict if item['completion_2'].endswith('.')]\n",
    "incomplete_completions_2 = [item['completion_2'] for item in list_data_dict if not item['completion_2'].endswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8012a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complete prompts: 495\n",
      "Number of incomplete prompts: 9725\n",
      "Number of complete completions_0: 6404\n",
      "Number of incomplete completions_0: 3816\n",
      "Number of complete completions_1: 6399\n",
      "Number of incomplete completions_1: 3821\n",
      "Number of complete completions_2: 6429\n",
      "Number of incomplete completions_2: 3791\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of complete prompts: {len(complete_prompts)}\")\n",
    "print(f\"Number of incomplete prompts: {len(incomplete_prompts)}\")\n",
    "print(f\"Number of complete completions_0: {len(complete_completions_0)}\")\n",
    "print(f\"Number of incomplete completions_0: {len(incomplete_completions_0)}\")\n",
    "print(f\"Number of complete completions_1: {len(complete_completions_1)}\")\n",
    "print(f\"Number of incomplete completions_1: {len(incomplete_completions_1)}\")\n",
    "print(f\"Number of complete completions_2: {len(complete_completions_2)}\")\n",
    "print(f\"Number of incomplete completions_2: {len(incomplete_completions_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cd9d5",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6857e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 길이 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5fd2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prompt'의 길이 고려\n",
    "lengths_prompt = [len(item['prompt']) for item in list_data_dict]\n",
    "\n",
    "# 각 'completion'의 길이 고려\n",
    "lengths_completion_0 = [len(item['completion_0']) for item in list_data_dict]\n",
    "lengths_completion_1 = [len(item['completion_1']) for item in list_data_dict]\n",
    "lengths_completion_2 = [len(item['completion_2']) for item in list_data_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1341760b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 'prompt' 길이 분포\n",
    "plt.hist(lengths_prompt, bins=50, color='blue', alpha=0.5, label='Prompt Lengths')\n",
    "\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8699cb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 각 'completion'의 길이 분포\n",
    "plt.hist(lengths_completion_0, bins=50, color='red', alpha=0.5, label='Completion_0 Lengths')\n",
    "plt.hist(lengths_completion_1, bins=50, color='green', alpha=0.5, label='Completion_1 Lengths')\n",
    "plt.hist(lengths_completion_2, bins=50, color='yellow', alpha=0.5, label='Completion_2 Lengths')\n",
    "\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69ca0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size: 10220\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original data size: {len(list_data_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67439a18",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fad9e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 기반 필터링 (지나치게 긴 문장이나 지나치게 짧은 문장을 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a969833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PROMPT_LENGTH = 5\n",
    "MAX_PROMPT_LENGTH = 50\n",
    "MIN_COMPLETION_LENGTH = 5\n",
    "MAX_COMPLETION_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c2ddf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    item for item in list_data_dict \n",
    "    if MIN_PROMPT_LENGTH <= len(item['prompt']) <= MAX_PROMPT_LENGTH\n",
    "    and MIN_COMPLETION_LENGTH <= len(item['completion_0']) <= MAX_COMPLETION_LENGTH\n",
    "    and MIN_COMPLETION_LENGTH <= len(item['completion_1']) <= MAX_COMPLETION_LENGTH\n",
    "    and MIN_COMPLETION_LENGTH <= len(item['completion_2']) <= MAX_COMPLETION_LENGTH\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96343949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data size: 8148\n"
     ]
    }
   ],
   "source": [
    "print(f\"Filtered data size: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19836786",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a33def04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거 ('prompt'와 'completion' 모두를 기반으로 중복 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ccb1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "unique_data = []\n",
    "for item in filtered_data:\n",
    "    combined_sentence = item['prompt'] + ' ' + item['completion_0'] + ' ' + item['completion_1'] + ' ' + item['completion_2']\n",
    "    if combined_sentence not in seen:\n",
    "        unique_data.append(item)\n",
    "        seen.add(combined_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3259fa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique data size after removing duplicates: 8148\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique data size after removing duplicates: {len(unique_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af93b72",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7abed",
   "metadata": {},
   "source": [
    "#### 02-3 데이터셋(RM) Augmentation\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "980b48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = []\n",
    "for item in filtered_data:\n",
    "    augmented_data.append(item)\n",
    "    prompt = item['prompt']\n",
    "    completion_0 = item['completion_0']\n",
    "    completion_1 = item['completion_1']\n",
    "    completion_2 = item['completion_2']\n",
    "\n",
    "    # For prompt augmentation\n",
    "    for new_prompt in augment_sentence(prompt):\n",
    "        new_data = item.copy()\n",
    "        new_data['prompt'] = new_prompt\n",
    "        augmented_data.append(new_data)\n",
    "\n",
    "    # For each completion augmentation\n",
    "    for new_completion_0 in augment_sentence(completion_0):\n",
    "        new_data = item.copy()\n",
    "        new_data['completion_0'] = new_completion_0\n",
    "        augmented_data.append(new_data)\n",
    "    \n",
    "    for new_completion_1 in augment_sentence(completion_1):\n",
    "        new_data = item.copy()\n",
    "        new_data['completion_1'] = new_completion_1\n",
    "        augmented_data.append(new_data)\n",
    "        \n",
    "    for new_completion_2 in augment_sentence(completion_2):\n",
    "        new_data = item.copy()\n",
    "        new_data['completion_2'] = new_completion_2\n",
    "        augmented_data.append(new_data)\n",
    "\n",
    "    if len(augmented_data) >= 15000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87e87047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data size: 15015\n"
     ]
    }
   ],
   "source": [
    "print(f\"Augmented data size: {len(augmented_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3397432",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6ce10",
   "metadata": {},
   "source": [
    "#### 02-4 변경 파일(전처리+증강) 저장\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "588a637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 경로 및 파일명\n",
    "file_path = '/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kogpt_trinity/kogpt_trinity_2_RM.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fcc5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 쓰기 모드로 파일 열기\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in augmented_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a94da",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f48b3",
   "metadata": {},
   "source": [
    "#### 03-1 데이터셋(POO) 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "128cc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a67c2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_3_PPO = '/aiffel/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b35e1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(list_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ada7a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'},\n",
       " {'prompt': '페르시아로부터 기원된 아랍요리의 특징이 뭐야'},\n",
       " {'prompt': '중화인민공화국의 기본 법률은 누가 제정 및 개정하는가?'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_data_dict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488b6f0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179bb138",
   "metadata": {},
   "source": [
    "#### 03-2 데이터셋(POO) EDA\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3182926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f7859d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문체 분류를 위한 기준\n",
    "def classify_tone(sentence):\n",
    "    if sentence.endswith('?'):\n",
    "        return \"질문형\"\n",
    "    elif sentence.endswith('.'):\n",
    "        return \"서술형\"\n",
    "    elif sentence.endswith('!'):\n",
    "        return \"감탄형\"\n",
    "    else:\n",
    "        return \"기타\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fbd5235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나? - Tone: 질문형\n",
      "----\n",
      "Prompt: 개포주공아파트는 몇 단지로 이루어져 있나? - Tone: 질문형\n",
      "----\n",
      "Prompt: 김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는? - Tone: 질문형\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 문체 분석\n",
    "for item in list_data_dict[:3]:\n",
    "    prompt = item['prompt']\n",
    "    \n",
    "    # 문체 분류\n",
    "    prompt_tone = classify_tone(prompt)\n",
    "    print(f\"Prompt: {prompt} - Tone: {prompt_tone}\")\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04343d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa2a577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 완성도 분석 (예시: 마지막에 마침표가 있는지로 판단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca293e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prompt'의 완성도 분석\n",
    "complete_prompts = [item['prompt'] for item in list_data_dict if item['prompt'].endswith('.')]\n",
    "incomplete_prompts = [item['prompt'] for item in list_data_dict if not item['prompt'].endswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2af96c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complete prompts: 588\n",
      "Number of incomplete prompts: 11412\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of complete prompts: {len(complete_prompts)}\")\n",
    "print(f\"Number of incomplete prompts: {len(incomplete_prompts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3091601",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7fe48637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 길이 분포 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "530eb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_prompt = [len(item['prompt']) for item in list_data_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8077da1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(lengths_prompt, bins=50, color='blue', alpha=0.5, label='Prompt Lengths')\n",
    "\n",
    "plt.title('Prompt Length Distribution')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of Prompts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc56e86",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14cd6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 기반 필터링 (지나치게 긴 문장이나 지나치게 짧은 문장을 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d740d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PROMPT_LENGTH = 5\n",
    "MAX_PROMPT_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d68d5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = [\n",
    "    item for item in list_data_dict \n",
    "    if MIN_PROMPT_LENGTH <= len(item['prompt']) <= MAX_PROMPT_LENGTH\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3113a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data size: 11482\n"
     ]
    }
   ],
   "source": [
    "print(f\"Filtered data size: {len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9bbee",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9dc429c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b88cef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "unique_data = []\n",
    "for item in filtered_data:\n",
    "    if item['prompt'] not in seen:\n",
    "        unique_data.append(item)\n",
    "        seen.add(item['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9a206345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique data size after removing duplicates: 11432\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique data size after removing duplicates: {len(unique_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0c7da",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d5b9cd",
   "metadata": {},
   "source": [
    "#### 03-3 데이터셋(POO) Augmentation\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d51197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = []\n",
    "for item in filtered_data:\n",
    "    augmented_data.append(item)\n",
    "    prompt = item['prompt']\n",
    "\n",
    "    # 'prompt' 증강\n",
    "    for new_prompt in augment_sentence(prompt):\n",
    "        new_data = item.copy()\n",
    "        new_data['prompt'] = new_prompt\n",
    "        augmented_data.append(new_data)\n",
    "\n",
    "    if len(augmented_data) >= 15000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6231f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented data size: 15000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Augmented data size: {len(augmented_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab9095",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7bf98",
   "metadata": {},
   "source": [
    "#### 03-4 변경 파일(전처리+증강) 저장\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df15b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된 경로 및 파일명\n",
    "file_path = '/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kogpt_trinity/kogpt_trinity_3_PPO.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d0d16bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 쓰기 모드로 파일 열기\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in augmented_data:\n",
    "        f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f2805",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5622b",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning (SFT)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf87cf2",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 불러오기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ef03aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf197e37",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e6b4b",
   "metadata": {},
   "source": [
    "#### 모델과 토크나이저 불러오기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "faea91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/ko-gpt-trinity-1.2B-v0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "04ddf3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/ko-gpt-trinity-1.2B-v0.5', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6055b3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/ko-gpt-trinity-1.2B-v0.5', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6345ea8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805e9f0",
   "metadata": {},
   "source": [
    "#### prompt 딕셔너리 템플릿과 SFT 데이터셋 클래스 정의 (모델 인퍼런스 단계에서 사용)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec5ce2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        data_path_1_SFT = '/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kogpt_trinity/kogpt_trinity_1_SFT.jsonl'\n",
    "        list_data_dict = []\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            for line in json_file:\n",
    "                list_data_dict.append(json.loads(line))\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "177c9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f54c1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4dec0810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 15004\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kogpt_trinity/kogpt_trinity_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "389e578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([30132, 42872, 33313, 30679, 40479, 39911,   384, 22509, 21921, 25372,\n",
      "          385, 31245, 23280, 34957, 25617, 36539, 29991, 25624, 25400, 31167,\n",
      "          376, 42872,   379, 46803,   456, 30303, 35353,   384, 25785, 20573,\n",
      "        37780,   383, 46900, 43226,   565, 27071, 23151, 31555, 41690, 35071,\n",
      "        25400, 31269, 32677, 30765, 31810, 36229, 30326, 33889, 30093, 34957,\n",
      "        25617, 30021, 30434, 29991, 39687, 34036, 19016, 31997, 49906, 19352,\n",
      "        30011, 30904, 36731, 43502, 30228, 31214, 30326, 29991, 31621, 33314,\n",
      "        34347, 30843, 50342, 33512, 31370, 34243, 29991, 35144, 32586, 32622,\n",
      "        44680, 30110, 21844, 39826, 34803, 31356, 39075, 30242, 36966, 29985,\n",
      "        34179, 36513, 30718, 35557, 32361, 31018, 29404, 35942, 19352, 41049,\n",
      "            1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,   383, 46900, 43226,   565, 27071, 23151, 31555, 41690, 35071,\n",
      "        25400, 31269, 32677, 30765, 31810, 36229, 30326, 33889, 30093, 34957,\n",
      "        25617, 30021, 30434, 29991, 39687, 34036, 19016, 31997, 49906, 19352,\n",
      "        30011, 30904, 36731, 43502, 30228, 31214, 30326, 29991, 31621, 33314,\n",
      "        34347, 30843, 50342, 33512, 31370, 34243, 29991, 35144, 32586, 32622,\n",
      "        44680, 30110, 21844, 39826, 34803, 31356, 39075, 30242, 36966, 29985,\n",
      "        34179, 36513, 30718, 35557, 32361, 31018, 29404, 35942, 19352, 41049,\n",
      "            1])\n"
     ]
    }
   ],
   "source": [
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19519b48",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91110456",
   "metadata": {},
   "source": [
    "#### 디코딩 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "0cf98734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea5c1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_token_ids(token_ids, tokenizer):\n",
    "    # token_ids를 Python 리스트로 변환\n",
    "    if isinstance(token_ids, torch.Tensor):\n",
    "        token_ids = token_ids.tolist()\n",
    "    \n",
    "    # token_ids 값을 디코딩\n",
    "    decoded_text = \"\"\n",
    "    for single_token_id in token_ids:\n",
    "        # -100 값은 무시\n",
    "        if single_token_id == -100:\n",
    "            continue\n",
    "        try:\n",
    "            decoded_text += tokenizer.decode([single_token_id], skip_special_tokens=True)\n",
    "        except OverflowError:\n",
    "            print(f\"Problematic token ID: {single_token_id}\")\n",
    "            raise\n",
    "    \n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f28bde",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f9f4e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 input_ids와 labels를 디코딩하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15142c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded input: ###Instruction(명령어):\n",
      "불고기용고기한우에요?\n",
      "\n",
      "###Response(응답):'저는인공지능챗봇이며,직접적으로식품에관한정보를가지고있지않습니다.하지만일반적으로불고기용고기는한우,쇠고기,돼지고기등다양한종류의고기를사용합니다.하지만한우는대표적인고급육류로알려져있기때문에,한우를사용하는경우도많습니다.알러지나개별건강상태에따라다를수있으니충분한정보수집후에선택해주시기바랍니다.\n",
      "Decoded output: '저는인공지능챗봇이며,직접적으로식품에관한정보를가지고있지않습니다.하지만일반적으로불고기용고기는한우,쇠고기,돼지고기등다양한종류의고기를사용합니다.하지만한우는대표적인고급육류로알려져있기때문에,한우를사용하는경우도많습니다.알러지나개별건강상태에따라다를수있으니충분한정보수집후에선택해주시기바랍니다.\n"
     ]
    }
   ],
   "source": [
    "input_text = decode_token_ids(train_dataset.input_ids[0], tokenizer)\n",
    "label_text = decode_token_ids(train_dataset.labels[0], tokenizer)\n",
    "\n",
    "print('Decoded input:', input_text)\n",
    "print('Decoded output:', label_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72914741",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c059a50",
   "metadata": {},
   "source": [
    "#### Training arguments를 사용해 trainer 클래스 정의\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3527f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test_trinity\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,  # 배치 크기를 줄임\n",
    "    per_device_eval_batch_size=2,   # 배치 크기를 줄임\n",
    "    gradient_accumulation_steps=4,  # 그래디언트 축적 사용\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69e2f6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ec1782bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 및 토크나이저를 GPU에서 삭제 후 다시 로드\n",
    "# del model\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19439849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 기타 메모리 최적화 기법\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e2f50",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2a759",
   "metadata": {},
   "source": [
    "#### SFT 훈련\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b84735ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 trainer.train()                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>model.save_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">'/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test_trinity/output_1_SF</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1662</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1659 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1660 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1662 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1664 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1929</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1926 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1927 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1928 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1929 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1930 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1931 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1932 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2699</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2696 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss_mb.reduce_mean().detach().to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.device)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2697 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2698 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss_context_manager():                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2699 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss(model, inputs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2700 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2701 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.n_gpu &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2702 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss = loss.mean()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># mean() to average on multi-gpu parallel training</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2731</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2728 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2729 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2730 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2731 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2732 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2733 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2734 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1075</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1072 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1073 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1074 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1075 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>transformer_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer(                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1076 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1077 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>past_key_values=past_key_values,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1078 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">899</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 896 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>encoder_attention_mask,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 897 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 898 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 899 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>outputs = block(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 900 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 901 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>layer_past=layer_past,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 902 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask=attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">389</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 386 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>) -&gt; Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 387 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>residual = hidden_states                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 388 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_1(hidden_states)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 389 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attn_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 390 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 391 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>layer_past=layer_past,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 392 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">311</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>key, value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.c_attn(encoder_hidden_states).split(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.split_size, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 309 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask = encoder_attention_mask                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 311 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>query, key, value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.c_attn(hidden_states).split(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.split_size, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 313 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>query = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._split_heads(query, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_heads, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.head_dim)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._split_heads(key, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_heads, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.head_dim)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pytorch_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">102</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>size_out = x.size()[:-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] + (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.nf,)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>102 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = torch.addmm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, x.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, x.size(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)), <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = x.view(size_out)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> x                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.76</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.57</span> GiB already \n",
       "allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.94</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 trainer.train()                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mmodel.save_pretrained(\u001b[33m'\u001b[0m\u001b[33m/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test_trinity/output_1_SF\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1662\u001b[0m in \u001b[92mtrain\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1659 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1660 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1662 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1664 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1929\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1926 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1927 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1928 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1929 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1930 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1931 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1932 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2699\u001b[0m in \u001b[92mtraining_step\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2696 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m loss_mb.reduce_mean().detach().to(\u001b[96mself\u001b[0m.args.device)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2697 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2698 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.compute_loss_context_manager():                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2699 \u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.compute_loss(model, inputs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2700 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2701 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.n_gpu > \u001b[94m1\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2702 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = loss.mean()  \u001b[2m# mean() to average on multi-gpu parallel training\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2731\u001b[0m in \u001b[92mcompute_loss\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2728 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = inputs.pop(\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2729 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2730 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2731 \u001b[2m│   │   \u001b[0moutputs = model(**inputs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2732 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save past state if it exists\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2733 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# TODO: this needs to be fixed and made cleaner later.\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2734 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.past_index >= \u001b[94m0\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m1075\u001b[0m in \u001b[92mforward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1072 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1073 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1074 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1075 \u001b[2m│   │   \u001b[0mtransformer_outputs = \u001b[96mself\u001b[0m.transformer(                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1076 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1077 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values=past_key_values,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1078 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m899\u001b[0m in \u001b[92mforward\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 896 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_attention_mask,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 897 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 898 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 899 \u001b[2m│   │   │   │   \u001b[0moutputs = block(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 900 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 901 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlayer_past=layer_past,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 902 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m389\u001b[0m in \u001b[92mforward\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 386 \u001b[0m\u001b[2m│   \u001b[0m) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 387 \u001b[0m\u001b[2m│   │   \u001b[0mresidual = hidden_states                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 388 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.ln_1(hidden_states)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 389 \u001b[2m│   │   \u001b[0mattn_outputs = \u001b[96mself\u001b[0m.attn(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 390 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 391 \u001b[0m\u001b[2m│   │   │   \u001b[0mlayer_past=layer_past,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 392 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/models/gpt2/\u001b[0m\u001b[1;33mmodeling_gpt2.py\u001b[0m:\u001b[94m311\u001b[0m in \u001b[92mforward\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   │   \u001b[0mkey, value = \u001b[96mself\u001b[0m.c_attn(encoder_hidden_states).split(\u001b[96mself\u001b[0m.split_size, dim=\u001b[94m2\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 309 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask = encoder_attention_mask                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 311 \u001b[2m│   │   │   \u001b[0mquery, key, value = \u001b[96mself\u001b[0m.c_attn(hidden_states).split(\u001b[96mself\u001b[0m.split_size, dim=\u001b[94m2\u001b[0m)  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 313 \u001b[0m\u001b[2m│   │   \u001b[0mquery = \u001b[96mself\u001b[0m._split_heads(query, \u001b[96mself\u001b[0m.num_heads, \u001b[96mself\u001b[0m.head_dim)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m\u001b[2m│   │   \u001b[0mkey = \u001b[96mself\u001b[0m._split_heads(key, \u001b[96mself\u001b[0m.num_heads, \u001b[96mself\u001b[0m.head_dim)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mpytorch_utils.py\u001b[0m:\u001b[94m102\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x):                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0msize_out = x.size()[:-\u001b[94m1\u001b[0m] + (\u001b[96mself\u001b[0m.nf,)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m102 \u001b[2m│   │   \u001b[0mx = torch.addmm(\u001b[96mself\u001b[0m.bias, x.view(-\u001b[94m1\u001b[0m, x.size(-\u001b[94m1\u001b[0m)), \u001b[96mself\u001b[0m.weight)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   │   \u001b[0mx = x.view(size_out)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m x                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m22.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.76\u001b[0m GiB total capacity; \u001b[1;36m13.57\u001b[0m GiB already \n",
       "allocated; \u001b[1;36m3.75\u001b[0m MiB free; \u001b[1;36m13.94\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
       "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test_trinity/output_1_SFT_trinity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea8ec88",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad873171",
   "metadata": {},
   "source": [
    "## foundation model의 교체는 성공하였으나, \n",
    "\n",
    "## 메모리 부족 문제로 더 이상 학습을 진행할 수 없으므로 \n",
    "\n",
    "## 본 과제는 여기서 종료함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269c243",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd28ce",
   "metadata": {},
   "source": [
    "#### 문장 생성 능력 확인 (generator 생성)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6e8f2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test/output_1_SFT_revised', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "56a04e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "63768996",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "def08c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7886e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5fe68fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이며, 실제 고기를 사용하지는 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 예를 들어 소갈비찜, 오리고기 구이, 양고기 바비큐 등 다양한 고기 요리를 할 수 있습니다. 하지만 정확한 정보를 얻기 위해서는\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'1953년입니다. attracted) '1953년 있습니다. 있는 대선 여깁니다. 대통령은 위해 워드. 닉슨은 수\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다.)은 미국에서 가장 빠르게 성장하는 공항 중 하나입니다.)은 미국 일리노이 주(Stiller)에 위치해 있으며, 국제선 항공권 예약이 가능합니다.)로 검색 엔진을 통해 해당 지역의 국제공항을 찾으실\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 농도는 어제와 비교해서 개선되었지만 아직도 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다. 미세먼지 농도를 확인하려면 해당 지역의 미세먼지 측정소에서 확인해보시는 것이 좋습니다.) 나아가는 미세먼지 때문에 개선되었습니다.\n"
     ]
    }
   ],
   "source": [
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5513b34",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1881cb0",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시 비우기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9aae3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7284651",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d772f",
   "metadata": {},
   "source": [
    "### Reward Model (RM)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be6b12",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 불러오기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aa7a121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd aiffel \n",
    "# git clone https://github.com/airobotlab/KoChatGPT  \n",
    "# cd KoChatGPT/colossalai_ChatGPT_230319/\n",
    "# pip install .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dd67ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad25cb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d11ec",
   "metadata": {},
   "source": [
    "#### Reward model 설계\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f60e4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6fdbb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a703d",
   "metadata": {},
   "source": [
    "#### 사용할 모델과 토크나이저 불러오기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f191a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ba0a7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7044ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cfa74b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1886fc14",
   "metadata": {},
   "source": [
    "#### ranking dataset 만들기 (RM 훈련시킬 때 사용)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "73519028",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_dict = []\n",
    "\n",
    "with open('/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kochatgpt/kochatgpt_2_RM_revised.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    for line in json_file:\n",
    "        list_data_dict.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b1cd9512",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_ranking2chosen = []\n",
    "\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "375f0baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 15015\n",
      "after  data num: 45045\n",
      "data example: \n",
      "{'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?', 'chosen': '구글상위노 이날 목송에서', 'rejected': '개포주공아파트는 다섯 단지로 이루어져 있습니다.'}\n"
     ]
    }
   ],
   "source": [
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153b3eb",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96ab2c",
   "metadata": {},
   "source": [
    "#### 완성한 ranking dataset을 shuffle한 후 훈련셋 만들기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a6ce9f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '전차가 어느 회사에서 처음 시험주행했어', 'chosen': '야 한다는 것', 'rejected': '요?\\n\\n전차는 1911년 미국의 캐딜락 엔진 기술 개발 기업인 슈타우트 모터 스쿼드(Studebaker Motor Squadron)에서 처음 시험주행했습니다.'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9954ce4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63d772ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "feae56bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1463.45it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1405.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17833b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3452dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋이 잘 만들어졌는지 하나를 뽑아 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "01c01e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "가자 지구와 어느 국가가 접해 있어\n",
      "######################################################################\n",
      "## chosen ##\n",
      "요?\n",
      "\n",
      "가장 가까운 국가는 미국입니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "국내 시장 공별 결과 같은 국육 강규 등 공개의 형개인 국육 강규인 국내 국내와 국내이 남겨둥칠 국가 공개 등 국육이 각국 국내 국내와 국내의 국가 공개 개인 국육 각국 국내 국내와 국내의 국가 공개 개인\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037b5b9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be762d",
   "metadata": {},
   "source": [
    "#### RM 학습\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e5ca3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b76b2c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:10,  1.01s/it]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<04:10,  1.01s/it, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:45,  1.10it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:45,  1.10it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:35,  1.14it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:35,  1.14it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:30,  1.17it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:30,  1.17it/s, loss=0.983]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:26,  1.19it/s, loss=0.983]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:26,  1.19it/s, loss=1.02] \u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:24,  1.19it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:24,  1.19it/s, loss=0.842]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:05<03:23,  1.20it/s, loss=0.842]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:23,  1.20it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:21,  1.20it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:21,  1.20it/s, loss=0.862]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:20,  1.20it/s, loss=0.862]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:20,  1.20it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:19,  1.20it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:19,  1.20it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:18,  1.20it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:18,  1.20it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:17,  1.20it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:17,  1.20it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:10<03:17,  1.20it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:10<03:17,  1.20it/s, loss=0.519]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:11<03:16,  1.20it/s, loss=0.519]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:11<03:16,  1.20it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:15,  1.20it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:15,  1.20it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:15,  1.20it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:15,  1.20it/s, loss=0.795]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:14,  1.20it/s, loss=0.795]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:14,  1.20it/s, loss=1.07] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:13,  1.20it/s, loss=1.07]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:13,  1.20it/s, loss=0.882]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:15<03:12,  1.20it/s, loss=0.882]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:12,  1.20it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:16<03:12,  1.20it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:16<03:12,  1.20it/s, loss=1.02] \u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:17<03:11,  1.20it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:17<03:11,  1.20it/s, loss=0.728]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:18<03:10,  1.20it/s, loss=0.728]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:18<03:10,  1.20it/s, loss=0.65] \u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:09,  1.20it/s, loss=0.65]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:09,  1.20it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:08,  1.20it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:08,  1.20it/s, loss=0.812]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:08,  1.20it/s, loss=0.812]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:08,  1.20it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:21<03:07,  1.19it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:21<03:07,  1.19it/s, loss=0.748]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:22<03:06,  1.19it/s, loss=0.748]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:22<03:06,  1.19it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:23<03:06,  1.19it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:23<03:06,  1.19it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:24<03:05,  1.19it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:24<03:05,  1.19it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:25<03:04,  1.19it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:25<03:04,  1.19it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:26<03:03,  1.19it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:26<03:03,  1.19it/s, loss=0.651]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:26<03:02,  1.19it/s, loss=0.651]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:26<03:02,  1.19it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:27<03:01,  1.19it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:27<03:01,  1.19it/s, loss=0.677]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:28<03:01,  1.19it/s, loss=0.677]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:28<03:01,  1.19it/s, loss=0.815]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:29<03:00,  1.19it/s, loss=0.815]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:29<03:00,  1.19it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:30<02:59,  1.19it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:30<02:59,  1.19it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:31<02:58,  1.19it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:31<02:58,  1.19it/s, loss=0.592]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:31<02:58,  1.19it/s, loss=0.592]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:31<02:58,  1.19it/s, loss=0.6]  \u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:32<02:57,  1.19it/s, loss=0.6]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:32<02:57,  1.19it/s, loss=0.666]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:33<02:56,  1.19it/s, loss=0.666]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:33<02:56,  1.19it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:34<02:55,  1.19it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:34<02:55,  1.19it/s, loss=0.608]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:35<02:54,  1.19it/s, loss=0.608]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:35<02:54,  1.19it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:36<02:54,  1.19it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:36<02:54,  1.19it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:36<02:53,  1.19it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:36<02:53,  1.19it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:37<02:52,  1.19it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:37<02:52,  1.19it/s, loss=0.748]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:38<02:52,  1.18it/s, loss=0.748]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:38<02:52,  1.18it/s, loss=0.62] \u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:39<02:51,  1.18it/s, loss=0.62]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:39<02:51,  1.18it/s, loss=0.881]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:40<02:50,  1.18it/s, loss=0.881]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:40<02:50,  1.18it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:41<02:49,  1.18it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:41<02:49,  1.18it/s, loss=0.995]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:42<02:48,  1.18it/s, loss=0.995]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:42<02:48,  1.18it/s, loss=0.649]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:42<02:47,  1.19it/s, loss=0.649]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:42<02:47,  1.19it/s, loss=0.449]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:43<02:47,  1.18it/s, loss=0.449]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:43<02:47,  1.18it/s, loss=0.569]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:44<02:46,  1.18it/s, loss=0.569]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:44<02:46,  1.18it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:45<02:45,  1.18it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:45<02:45,  1.18it/s, loss=0.32] \u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:46<02:44,  1.18it/s, loss=0.32]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:46<02:44,  1.18it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:47<02:44,  1.18it/s, loss=0.686]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:47<02:44,  1.18it/s, loss=0.257]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:47<02:43,  1.18it/s, loss=0.257]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:47<02:43,  1.18it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:48<02:42,  1.18it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:48<02:42,  1.18it/s, loss=0.546]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:49<02:42,  1.18it/s, loss=0.546]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:49<02:42,  1.18it/s, loss=0.356]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:50<02:41,  1.18it/s, loss=0.356]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:50<02:41,  1.18it/s, loss=0.984]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:51<02:40,  1.18it/s, loss=0.984]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:51<02:40,  1.18it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:52<02:39,  1.18it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:52<02:39,  1.18it/s, loss=0.252]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:53<02:38,  1.18it/s, loss=0.252]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:53<02:38,  1.18it/s, loss=0.324]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:53<02:38,  1.18it/s, loss=0.324]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:53<02:38,  1.18it/s, loss=0.44] \u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:54<02:37,  1.18it/s, loss=0.44]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:54<02:37,  1.18it/s, loss=0.187]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:55<02:36,  1.17it/s, loss=0.187]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:55<02:36,  1.17it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:56<02:35,  1.17it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:56<02:35,  1.17it/s, loss=0.206]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:57<02:34,  1.17it/s, loss=0.206]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:57<02:34,  1.17it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [00:58<02:33,  1.18it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [00:58<02:33,  1.18it/s, loss=0.318]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [00:59<02:33,  1.17it/s, loss=0.318]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [00:59<02:33,  1.17it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [00:59<02:32,  1.17it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [00:59<02:32,  1.17it/s, loss=0.759]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:00<02:31,  1.17it/s, loss=0.759]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:00<02:31,  1.17it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:01<02:30,  1.17it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:01<02:30,  1.17it/s, loss=0.439] \u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:02<02:30,  1.17it/s, loss=0.439]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:02<02:30,  1.17it/s, loss=1.5]  \u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:03<02:29,  1.17it/s, loss=1.5]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:03<02:29,  1.17it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:04<02:28,  1.17it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:04<02:28,  1.17it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:04<02:27,  1.17it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:05<02:27,  1.17it/s, loss=0.863]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:05<02:26,  1.17it/s, loss=0.863]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:05<02:26,  1.17it/s, loss=0.489]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:06<02:26,  1.17it/s, loss=0.489]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:06<02:26,  1.17it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:07<02:25,  1.17it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:07<02:25,  1.17it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:08<02:24,  1.17it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:08<02:24,  1.17it/s, loss=0.592]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:09<02:23,  1.17it/s, loss=0.592]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:09<02:23,  1.17it/s, loss=0.704]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:10<02:22,  1.17it/s, loss=0.704]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:10<02:22,  1.17it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:10<02:21,  1.17it/s, loss=0.643]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:10<02:21,  1.17it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:11<02:21,  1.17it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:11<02:21,  1.17it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:12<02:20,  1.17it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:12<02:20,  1.17it/s, loss=0.514]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:13<02:19,  1.17it/s, loss=0.514]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:13<02:19,  1.17it/s, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:14<02:18,  1.17it/s, loss=0.464]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:14<02:18,  1.17it/s, loss=0.487]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:15<02:17,  1.17it/s, loss=0.487]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:15<02:17,  1.17it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:16<02:16,  1.17it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:16<02:16,  1.17it/s, loss=1.15] \u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:16<02:16,  1.17it/s, loss=1.15]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:16<02:16,  1.17it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:17<02:15,  1.17it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:17<02:15,  1.17it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:18<02:14,  1.17it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:18<02:14,  1.17it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:19<02:13,  1.17it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:19<02:13,  1.17it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:20<02:12,  1.17it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:20<02:12,  1.17it/s, loss=0.963]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:21<02:12,  1.17it/s, loss=0.963]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:21<02:12,  1.17it/s, loss=0.515]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:22<02:11,  1.16it/s, loss=0.515]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:22<02:11,  1.16it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:22<02:10,  1.16it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:23<02:10,  1.16it/s, loss=0.874]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:23<02:09,  1.16it/s, loss=0.874]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:23<02:09,  1.16it/s, loss=0.54] \u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:24<02:08,  1.16it/s, loss=0.54]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:24<02:08,  1.16it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:25<02:07,  1.17it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:25<02:07,  1.17it/s, loss=1.03] \u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:26<02:06,  1.17it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:26<02:06,  1.17it/s, loss=0.692]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:27<02:06,  1.17it/s, loss=0.692]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:27<02:06,  1.17it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:28<02:05,  1.17it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:28<02:05,  1.17it/s, loss=0.418]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:28<02:04,  1.16it/s, loss=0.418]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:29<02:04,  1.16it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:29<02:03,  1.17it/s, loss=0.601]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:29<02:03,  1.17it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:30<02:02,  1.16it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:30<02:02,  1.16it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:31<02:01,  1.17it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:31<02:01,  1.17it/s, loss=0.828]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:32<02:01,  1.16it/s, loss=0.828]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:32<02:01,  1.16it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:33<02:00,  1.16it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:33<02:00,  1.16it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:34<01:59,  1.16it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:34<01:59,  1.16it/s, loss=0.59] \u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:35<01:58,  1.16it/s, loss=0.59]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:35<01:58,  1.16it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:35<01:57,  1.16it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:35<01:57,  1.16it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:36<01:56,  1.16it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:36<01:56,  1.16it/s, loss=0.45] \u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:37<01:56,  1.16it/s, loss=0.45]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:37<01:56,  1.16it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:38<01:55,  1.16it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:38<01:55,  1.16it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:39<01:54,  1.16it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:39<01:54,  1.16it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:40<01:53,  1.16it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:40<01:53,  1.16it/s, loss=1.01] \u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:41<01:52,  1.16it/s, loss=1.01]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:41<01:52,  1.16it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:41<01:52,  1.16it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:41<01:52,  1.16it/s, loss=0.433]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:42<01:51,  1.16it/s, loss=0.433]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:42<01:51,  1.16it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:43<01:50,  1.16it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:43<01:50,  1.16it/s, loss=0.671]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:44<01:49,  1.16it/s, loss=0.671]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:44<01:49,  1.16it/s, loss=0.385]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:45<01:48,  1.16it/s, loss=0.385]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:45<01:48,  1.16it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:46<01:47,  1.16it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:46<01:47,  1.16it/s, loss=0.63] \u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:47<01:47,  1.16it/s, loss=0.63]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:47<01:47,  1.16it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:47<01:46,  1.16it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:47<01:46,  1.16it/s, loss=0.928]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:48<01:45,  1.16it/s, loss=0.928]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:48<01:45,  1.16it/s, loss=1.01] \u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:49<01:44,  1.16it/s, loss=1.01]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:49<01:44,  1.16it/s, loss=1.37]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:50<01:43,  1.15it/s, loss=1.37]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:50<01:43,  1.15it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:51<01:42,  1.16it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:51<01:42,  1.16it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:52<01:41,  1.16it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:52<01:41,  1.16it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:53<01:41,  1.16it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:53<01:41,  1.16it/s, loss=0.433]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:54<01:40,  1.16it/s, loss=0.433]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:54<01:40,  1.16it/s, loss=0.565]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:54<01:39,  1.16it/s, loss=0.565]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:54<01:39,  1.16it/s, loss=0.659]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:55<01:38,  1.15it/s, loss=0.659]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:55<01:38,  1.15it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [01:56<01:37,  1.15it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [01:56<01:37,  1.15it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [01:57<01:37,  1.15it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [01:57<01:37,  1.15it/s, loss=0.856]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [01:58<01:36,  1.15it/s, loss=0.856]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [01:58<01:36,  1.15it/s, loss=0.777]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [01:59<01:35,  1.15it/s, loss=0.777]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [01:59<01:35,  1.15it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:00<01:34,  1.15it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:00<01:34,  1.15it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:00<01:33,  1.15it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:00<01:33,  1.15it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:01<01:32,  1.15it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:01<01:32,  1.15it/s, loss=0.53] \u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:02<01:31,  1.15it/s, loss=0.53]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:02<01:31,  1.15it/s, loss=0.421]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:03<01:31,  1.15it/s, loss=0.421]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:03<01:31,  1.15it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:04<01:30,  1.15it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:04<01:30,  1.15it/s, loss=0.397]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:05<01:29,  1.15it/s, loss=0.397]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:05<01:29,  1.15it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:06<01:28,  1.15it/s, loss=0.647]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:06<01:28,  1.15it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:07<01:27,  1.15it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:07<01:27,  1.15it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:07<01:26,  1.15it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:07<01:26,  1.15it/s, loss=1.4]  \u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:08<01:26,  1.15it/s, loss=1.4]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:08<01:26,  1.15it/s, loss=0.493]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:09<01:25,  1.15it/s, loss=0.493]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:09<01:25,  1.15it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:10<01:24,  1.15it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:10<01:24,  1.15it/s, loss=0.316]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:11<01:23,  1.15it/s, loss=0.316]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:11<01:23,  1.15it/s, loss=0.72] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:12<01:22,  1.15it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:12<01:22,  1.15it/s, loss=0.43]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:13<01:21,  1.15it/s, loss=0.43]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:13<01:21,  1.15it/s, loss=0.35]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:13<01:20,  1.15it/s, loss=0.35]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:14<01:20,  1.15it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:14<01:20,  1.15it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:14<01:20,  1.15it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:15<01:19,  1.15it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:15<01:19,  1.15it/s, loss=0.402]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:16<01:18,  1.15it/s, loss=0.402]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:16<01:18,  1.15it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:17<01:17,  1.15it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:17<01:17,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:18<01:16,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:18<01:16,  1.15it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:19<01:15,  1.15it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:19<01:15,  1.15it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:20<01:14,  1.15it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:20<01:14,  1.15it/s, loss=0.886]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:20<01:13,  1.15it/s, loss=0.886]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:20<01:13,  1.15it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:21<01:13,  1.15it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:21<01:13,  1.15it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:22<01:12,  1.15it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:22<01:12,  1.15it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:23<01:11,  1.15it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:23<01:11,  1.15it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:24<01:10,  1.15it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:24<01:10,  1.15it/s, loss=0.871]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:25<01:09,  1.15it/s, loss=0.871]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:25<01:09,  1.15it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:26<01:08,  1.15it/s, loss=0.744]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:26<01:08,  1.15it/s, loss=0.64] \u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:27<01:07,  1.15it/s, loss=0.64]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:27<01:07,  1.15it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:27<01:07,  1.15it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:27<01:07,  1.15it/s, loss=0.843]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:28<01:06,  1.15it/s, loss=0.843]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:28<01:06,  1.15it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:29<01:05,  1.15it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:29<01:05,  1.15it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:30<01:04,  1.15it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:30<01:04,  1.15it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:31<01:03,  1.15it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:31<01:03,  1.15it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:32<01:02,  1.15it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:32<01:02,  1.15it/s, loss=0.715]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:33<01:01,  1.15it/s, loss=0.715]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:33<01:01,  1.15it/s, loss=0.911]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:34<01:01,  1.14it/s, loss=0.911]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:34<01:01,  1.14it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:34<01:00,  1.15it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:34<01:00,  1.15it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:35<00:59,  1.15it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:35<00:59,  1.15it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:36<00:58,  1.15it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:36<00:58,  1.15it/s, loss=0.779]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:37<00:57,  1.15it/s, loss=0.779]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:37<00:57,  1.15it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:38<00:56,  1.15it/s, loss=0.696]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:38<00:56,  1.15it/s, loss=0.677]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:39<00:55,  1.15it/s, loss=0.677]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:39<00:55,  1.15it/s, loss=0.975]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:40<00:54,  1.15it/s, loss=0.975]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:40<00:54,  1.15it/s, loss=0.478]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:41<00:54,  1.15it/s, loss=0.478]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:41<00:54,  1.15it/s, loss=0.743]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:41<00:53,  1.14it/s, loss=0.743]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:41<00:53,  1.14it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:42<00:52,  1.14it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:42<00:52,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:43<00:51,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:43<00:51,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:44<00:50,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:44<00:50,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:45<00:49,  1.14it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:45<00:49,  1.14it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:46<00:49,  1.14it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:46<00:49,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:47<00:48,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:47<00:48,  1.14it/s, loss=0.618]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:48<00:47,  1.14it/s, loss=0.618]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:48<00:47,  1.14it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:48<00:46,  1.14it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:48<00:46,  1.14it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:49<00:45,  1.14it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:49<00:45,  1.14it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:50<00:44,  1.14it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:50<00:44,  1.14it/s, loss=0.809]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:51<00:43,  1.14it/s, loss=0.809]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:51<00:43,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:52<00:42,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:52<00:42,  1.14it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:53<00:42,  1.14it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:53<00:42,  1.14it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:54<00:41,  1.14it/s, loss=0.564]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:54<00:41,  1.14it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:55<00:40,  1.14it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:55<00:40,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:55<00:39,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:55<00:39,  1.14it/s, loss=0.566]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [02:56<00:38,  1.14it/s, loss=0.566]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [02:56<00:38,  1.14it/s, loss=0.717]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [02:57<00:37,  1.14it/s, loss=0.717]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [02:57<00:37,  1.14it/s, loss=0.63] \u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [02:58<00:36,  1.14it/s, loss=0.63]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [02:58<00:36,  1.14it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [02:59<00:35,  1.14it/s, loss=0.631]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [02:59<00:35,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:00<00:35,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:00<00:35,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:01<00:34,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:01<00:34,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:02<00:33,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:02<00:33,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:02<00:32,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:02<00:32,  1.14it/s, loss=0.58] \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:03<00:31,  1.14it/s, loss=0.58]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:03<00:31,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:04<00:30,  1.14it/s, loss=0.504]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:04<00:30,  1.14it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:05<00:29,  1.14it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:05<00:29,  1.14it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:06<00:28,  1.14it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:06<00:28,  1.14it/s, loss=0.86] \u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:07<00:28,  1.14it/s, loss=0.86]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:07<00:28,  1.14it/s, loss=0.777]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:08<00:27,  1.14it/s, loss=0.777]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:08<00:27,  1.14it/s, loss=0.364]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:09<00:26,  1.14it/s, loss=0.364]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:09<00:26,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:09<00:25,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:09<00:25,  1.14it/s, loss=0.74] \u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:10<00:24,  1.14it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:10<00:24,  1.14it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:11<00:23,  1.14it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:11<00:23,  1.14it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:12<00:22,  1.14it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:12<00:22,  1.14it/s, loss=0.227]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:13<00:21,  1.14it/s, loss=0.227]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:13<00:21,  1.14it/s, loss=0.86] \u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:14<00:21,  1.14it/s, loss=0.86]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:14<00:21,  1.14it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:15<00:20,  1.14it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:15<00:20,  1.14it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:16<00:19,  1.14it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:16<00:19,  1.14it/s, loss=0.379]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:16<00:18,  1.14it/s, loss=0.379]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:16<00:18,  1.14it/s, loss=0.336]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:17<00:17,  1.14it/s, loss=0.336]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:17<00:17,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:18<00:16,  1.14it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:18<00:16,  1.14it/s, loss=0.422]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:19<00:15,  1.14it/s, loss=0.422]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:19<00:15,  1.14it/s, loss=0.294]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:20<00:14,  1.14it/s, loss=0.294]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:20<00:14,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:21<00:14,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:21<00:14,  1.14it/s, loss=0.393]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:22<00:13,  1.14it/s, loss=0.393]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:22<00:13,  1.14it/s, loss=0.317]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:23<00:12,  1.14it/s, loss=0.317]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:23<00:12,  1.14it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:23<00:11,  1.14it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:24<00:11,  1.14it/s, loss=0.924]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:24<00:10,  1.14it/s, loss=0.924]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:24<00:10,  1.14it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:25<00:09,  1.14it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:25<00:09,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:26<00:08,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:26<00:08,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:27<00:07,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:27<00:07,  1.14it/s, loss=0.146]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:28<00:07,  1.14it/s, loss=0.146]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:28<00:07,  1.14it/s, loss=0.805]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:29<00:06,  1.14it/s, loss=0.805]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:29<00:06,  1.14it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:30<00:05,  1.14it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:30<00:05,  1.14it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:31<00:04,  1.14it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:31<00:04,  1.14it/s, loss=0.251]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:31<00:03,  1.14it/s, loss=0.251]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:31<00:03,  1.14it/s, loss=0.368]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:32<00:02,  1.14it/s, loss=0.368]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:32<00:02,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:33<00:01,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:33<00:01,  1.14it/s, loss=1.23] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:34<00:00,  1.14it/s, loss=1.23]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:34<00:00,  1.14it/s, loss=0.333]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:35<00:00,  1.14it/s, loss=0.333]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:49<00:00, 229.89s/it]0,  1.14it/s, loss=0.6]  \u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.652, dist_mean=0.515]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:49<00:00, 229.90s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test/output_2_RM_revised')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d6bc3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4fa25",
   "metadata": {},
   "source": [
    "#### RM 학습 여부 확인 (임의의 문장의 입력에 대한 reward score 출력 확인)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6b559e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d77551",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "78dddab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: 2.4\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "981d5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: 2.9\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7fcc0a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: 3.0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bf99527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 2.7\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e89b0d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe869190",
   "metadata": {},
   "source": [
    "#### 메모리 관리를 위해 캐시 비우기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dc284e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb9c046",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a83f0",
   "metadata": {},
   "source": [
    "### Proximal Policy Optimization (PPO)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38cbb97",
   "metadata": {},
   "source": [
    "#### 필요 라이브러리 불러오기\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c71113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa61d9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4caa221",
   "metadata": {},
   "source": [
    "#### pretrain 모델인 kogpt-2의 토크나이저를 그대로 사용\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "38062cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test/output_1_SFT_revised', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test/output_2_RM_revised', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a2412d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a10a34",
   "metadata": {},
   "source": [
    "#### 모델학습에 사용할 옵티마이저와 모델 준비\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a100c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4afddc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb5b45",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea152006",
   "metadata": {},
   "source": [
    "#### PPO 학습에 쓸 데이터를 불러와 토크나이징\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "69751342",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_dict = []\n",
    "\n",
    "with open('/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/data_kochatgpt/kochatgpt_3_PPO_revised.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    for line in json_file:\n",
    "        list_data_dict.append(json.loads(line))\n",
    "        \n",
    "list_prompt = [tmp['prompt'] for tmp in list_data_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e69737f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9f0cb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1dbca80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0438d7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a90c2f",
   "metadata": {},
   "source": [
    "#### PPO 학습\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "54b1c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c0563b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.60s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00142]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.70it/s, actor_loss=0, critic_loss=0.00142]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.70it/s, actor_loss=0, critic_loss=0.0832] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0, critic_loss=0.0832]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0, critic_loss=0.00237]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s, actor_loss=0, critic_loss=0.00237]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:18<00:00,  6.11s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.49s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.176, critic_loss=0.0341]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.95it/s, actor_loss=-.176, critic_loss=0.0341]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.95it/s, actor_loss=-.156, critic_loss=0.0542]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s, actor_loss=-.156, critic_loss=0.0542]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s, actor_loss=-.145, critic_loss=0.0218]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s, actor_loss=-.145, critic_loss=0.0218]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:18<00:00,  6.02s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.50s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0162, critic_loss=0.00318]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s, actor_loss=-.0162, critic_loss=0.00318]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.92it/s, actor_loss=-.0209, critic_loss=0.0129] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=-.0209, critic_loss=0.0129]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0.0238, critic_loss=0.0608]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s, actor_loss=0.0238, critic_loss=0.0608]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:18<00:00,  6.08s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.71s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.213, critic_loss=0.0955]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.93it/s, actor_loss=0.213, critic_loss=0.0955]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.93it/s, actor_loss=0.796, critic_loss=1]     \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0.796, critic_loss=1]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0.753, critic_loss=0.887]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s, actor_loss=0.753, critic_loss=0.887]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:18<00:00,  6.18s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.106, critic_loss=0.116]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.91it/s, actor_loss=-.106, critic_loss=0.116]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.91it/s, actor_loss=-.212, critic_loss=0.182]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=-.212, critic_loss=0.182]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.91it/s, actor_loss=-.2, critic_loss=0.23]   \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.91it/s, actor_loss=-.2, critic_loss=0.23]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:18<00:00,  6.24s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.31, critic_loss=0.16]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=-.31, critic_loss=0.16]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=-.369, critic_loss=0.133]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.369, critic_loss=0.133]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.90it/s, actor_loss=-.374, critic_loss=0.0604]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s, actor_loss=-.374, critic_loss=0.0604]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:18<00:00,  6.28s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.79s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.048, critic_loss=0.00783]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.048, critic_loss=0.00783]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0363, critic_loss=0.0119]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0363, critic_loss=0.0119]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.079, critic_loss=0.0279] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.079, critic_loss=0.0279]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.34s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.89s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.335, critic_loss=0.0877]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.335, critic_loss=0.0877]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.324, critic_loss=0.105] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.324, critic_loss=0.105]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.264, critic_loss=0.0693]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.264, critic_loss=0.0693]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:19<00:00,  6.40s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.88s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.316, critic_loss=0.0784]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.316, critic_loss=0.0784]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.258, critic_loss=0.0234]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.258, critic_loss=0.0234]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.274, critic_loss=0.014] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.274, critic_loss=0.014]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:19<00:00,  6.38s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.89s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0131, critic_loss=0.0042]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.0131, critic_loss=0.0042]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.039, critic_loss=0.0201] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.039, critic_loss=0.0201]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.00726, critic_loss=0.0211]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.00726, critic_loss=0.0211]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:19<00:00,  6.41s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('/aiffel/aiffel/AIFFEL/09_GD_NLP/Quest_09/test/output_3_PPO_revised')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151fa74",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a6bc2",
   "metadata": {},
   "source": [
    "#### RLHF가 적용된 koGPT-2의 생성능력 확인\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6da9a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dbb26ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b5f495ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "98eb8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b0d44bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 AI 어시스턴트로, 답변해드리도록 노력하겠습니다.\\n일반적으로 불고기용 고기는 한우와 쌀을 혼합하거나 첨가물을 사용하지 않으면서 사용됩니다. 이러한 방식으로 불고기의 사용방법을 선택하며, 부위나 종류는 직접 정보를 사용합니다. 예를 들어 생선과 쇠고기, 돼지고기 등의 쇠고기를 사용한다는 것은 가능할 수 있습니다. 하지만 개별 레시피를 따라서, 또는 부위나 지역의 요리를 따라 활용하기 때문에 고기 한우의 사용 여부는 상황에 따라 다릅니다. 참조\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'1956년입니다. 닉슨은 1960년 부통령직을 부통령 재직 당시였습니다.)한 부통령은)한 하지만 능력을 압제를 후 않았습니다. 1952년)한 수 대선) 졌습니다. 대선 '1957년\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'시카고 오헤어 국제공항은 미국 일리노이 주 시카고에 위치해 있습니다. 현재 시카고에 가장 미국 항공 여행객들이 많은 도시는 미국 일리노이 주 시카고에 해당하는 주 시카고에 있는 공항입니다. hem\\'s AI: 국제공항 (PK) heavy) atomic net bradypus transition, physical information: 미국 항공권 챗봇입니다.) 미국에서) 미국에서)를)\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 농도는 어제와 비교해서 개선되었지만 아직 나쁜 수준이며, 개선되지 않았기 때문에 측정소에서 미세먼지 농도를 확인할 수 없습니다. 미세먼지의 농도는 개선되었지만 여전히 나쁜 수준이며, 마스크 착용과 실외 활동 자제를 권장합니다. 개선되어야 할 것입니다. 개선되어야 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2869e9",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c603d8b",
   "metadata": {},
   "source": [
    "## 27-2. 프로젝트 제출\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536f767",
   "metadata": {},
   "source": [
    "### 루브릭\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507db20",
   "metadata": {},
   "source": [
    "|<big>평가문항</big>|<big>상세기준</big>|\n",
    "|:--|:--|\n",
    "|<br>**1. 기존 데이터셋을 추가 정제하고, generation 성능을 끌어올리기 위한 기법들을 실험해 모델 perfomance를 향상시켜보았는가?**<br><br> | <br>기존 데이터셋의 문제점을 분석하고 전처리 전략을 수립해 추가 정제를 진행했다. Beam search, Top-k(p) sampling 등 최선의 디코딩 전략을 수립해 향상된 모델 추론 결과를 제시했다. BLEU, ROUGE 등 생성된 텍스트를 평가하기 위한 메트릭을 적용한 정량적인 평가 결과와 주관적인 평가를 비교분석하였다.<br><br> |\n",
    "|<br>**2. 새로운 데이터를 수집해 전처리를 수행하여 모델을 재학습시켜보았는가?**<br><br> | <br>모두의 말뭉치, AI hub 등에 공개된 데이터를 사용해 추가 데이터셋을 구축하기 위한 기준과 근거를 수립했다. ChatGPT API나 다양한 한국어 benchmark 데이터셋을 활용해 Human Feedback 을 대체할 수 있는 아이디어를 구현했다. 위를 바탕으로 SFT, RM, PPO 세 단계에 필요한 각 데이터셋을 적절히 구축하여, 모델 추론 결과와 수립한 가설을 비교해보았다.<br><br> |\n",
    "|<br>**3. 학습 전략 또는 foundation model을 변경해 모델을 재학습시켜보았는가?**<br><br> | <br>더 적절한 Instruction Tuning 기법을 적용해 SFT를 해보거나, Reward Model의 ranking algorithm을 개선해보았다. KoGPT-2가 아닌 다른 모델을 initial model로 사용하여 모델 학습을 성공시켰다. 허깅페이스의 accelerate, bitsandbytes 라이브러리 등을 사용하여 더 큰 스케일의 모델로 ChatGPT를 re-building해 모델 성능을 향상시켰다.<br><br> |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
